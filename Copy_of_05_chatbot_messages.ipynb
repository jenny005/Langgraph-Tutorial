{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenny005/Langgraph-Tutorial/blob/main/Copy_of_05_chatbot_messages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "X-3xrp2u-wW8",
        "outputId": "260da407-972d-4c33-b21c-d09d5879c2b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 1)) (4.14.1)\n",
            "Collecting typing (from -r /content/requirements.txt (line 2))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langgraph (from -r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph-0.6.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai (from -r /content/requirements.txt (line 4))\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 5)) (0.3.74)\n",
            "Collecting langgraph-checkpoint-mongodb (from -r /content/requirements.txt (line 6))\n",
            "  Downloading langgraph_checkpoint_mongodb-0.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community (from -r /content/requirements.txt (line 7))\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting python-dotenv (from -r /content/requirements.txt (line 8))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 9)) (0.2.65)\n",
            "Collecting pymongo (from -r /content/requirements.txt (line 10))\n",
            "  Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting wikipedia (from -r /content/requirements.txt (line 11))\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trustcall (from -r /content/requirements.txt (line 12))\n",
            "  Downloading trustcall-0.0.39-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting langchain-mcp-adapters (from -r /content/requirements.txt (line 13))\n",
            "  Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r /content/requirements.txt (line 3)) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r /content/requirements.txt (line 3)) (3.5.0)\n",
            "Collecting openai<2.0.0,>=1.99.9 (from langchain_openai->-r /content/requirements.txt (line 4))\n",
            "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->-r /content/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (25.0)\n",
            "Collecting langchain-mongodb>=0.6.1 (from langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading langchain_mongodb-0.6.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting motor>3.6.0 (from langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading motor-3.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pymongo (from -r /content/requirements.txt (line 10))\n",
            "  Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (15.0.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo->-r /content/requirements.txt (line 10))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting dydantic<1.0.0,>=0.0.8 (from trustcall->-r /content/requirements.txt (line 12))\n",
            "  Downloading dydantic-0.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting mcp>=1.9.2 (from langchain-mcp-adapters->-r /content/requirements.txt (line 13))\n",
            "  Downloading mcp-1.13.0-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.20.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r /content/requirements.txt (line 9)) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (2025.8.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r /content/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community->-r /content/requirements.txt (line 7)) (0.3.9)\n",
            "Collecting lark<2.0.0,>=1.1.9 (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core->-r /content/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core->-r /content/requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (4.25.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13))\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.47.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r /content/requirements.txt (line 7)) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai->-r /content/requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (2.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (8.2.1)\n",
            "Downloading langgraph-0.6.5-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint_mongodb-0.1.4-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trustcall-0.0.39-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dydantic-0.0.8-py3-none-any.whl (8.6 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langchain_mongodb-0.6.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.13.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.7.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: typing, wikipedia\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=e5bc26790e1ce3d4f388cb46dd9ff5c3ba22472a0c241e82baa0edcbea4abe19\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=cbed6bc5e82eb8e7d68d7bcbbbc76c80597cfaac91b3a169d4a783c57653187a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built typing wikipedia\n",
            "Installing collected packages: typing, python-dotenv, ormsgpack, mypy-extensions, marshmallow, lark, httpx-sse, dnspython, wikipedia, typing-inspect, sse-starlette, pymongo, pydantic-settings, openai, motor, langgraph-sdk, dydantic, dataclasses-json, mcp, langgraph-checkpoint, langchain_openai, langchain-mcp-adapters, langgraph-prebuilt, langgraph, langchain-mongodb, langchain_community, trustcall, langgraph-checkpoint-mongodb\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.8\n",
            "    Uninstalling openai-1.99.8:\n",
            "      Successfully uninstalled openai-1.99.8\n",
            "Successfully installed dataclasses-json-0.6.7 dnspython-2.7.0 dydantic-0.0.8 httpx-sse-0.4.1 langchain-mcp-adapters-0.1.9 langchain-mongodb-0.6.2 langchain_community-0.3.27 langchain_openai-0.3.30 langgraph-0.6.5 langgraph-checkpoint-2.1.1 langgraph-checkpoint-mongodb-0.1.4 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 lark-1.2.2 marshmallow-3.26.1 mcp-1.13.0 motor-3.7.1 mypy-extensions-1.1.0 openai-1.99.9 ormsgpack-1.10.0 pydantic-settings-2.10.1 pymongo-4.12.1 python-dotenv-1.1.1 sse-starlette-3.0.2 trustcall-0.0.39 typing-3.7.4.3 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "9ee8e98ce3334bc19ec83f7560847137"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv  # load environment variables from a .env file into your program’s os.environ dictionary\n",
        "load_dotenv(\"/content/.env\", override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4Ts6nwI-xqb",
        "outputId": "1325f87a-2384-4ae8-f4e0-08841a819dce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jqVAyhwb-taC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "9150d89b-eb62-4ac9-8f12-89d8cdeae407"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import MessagesState\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from IPython.display import Image, display\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "import json\n",
        "\n",
        "\n",
        "# OPENAI_API_KEY environment variable must be set\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "\n",
        "# Defining Agent's node\n",
        "##################################################################################\n",
        "\n",
        "# System message\n",
        "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
        "You are a helpful and knowledgeable chatbot assistant.\n",
        "Your goal is to provide clear and accurate answers to user questions based on the information they provide.\n",
        "Stay focused, concise, and ensure your responses are relevant to the context of the conversation.\n",
        "If you don’t have enough information, ask for clarification.”\n",
        "\"\"\"))\n",
        "\n",
        "# Node\n",
        "def chatbot(state: MessagesState):\n",
        "   return {\"messages\": [llm.invoke([chatbot_system_message] + state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# Defining Graph\n",
        "##################################################################################\n",
        "\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "chatbot_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Show\n",
        "display(Image(chatbot_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VWmsg8xX-taF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f8b65e-6123-46d5-9cb3-09da2efa8aa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='02a740cc-0eab-4d19-8ded-641ae8df7b4c'),\n",
              "  AIMessage(content=\"I can help with that! Could you provide more details about the specific issues you're facing with the API responses? For example, are you having trouble with parsing the response, handling errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 89, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C4ou32ZHs7anUPVu2sWZNMuNZ6hNa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--701a7af0-1d6b-44ad-9611-ba383a3b30cb-0', usage_metadata={'input_tokens': 89, 'output_tokens': 41, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "thread_id = \"2\" # checkpoints are saved to a thread which can be accessed after graph execution\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}} # when invoking a graph with checkpointer, you must specify a thread_id as part of configurable pointion of the config\n",
        "\n",
        "chatbot_graph.invoke({\"messages\": [HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")]}, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VWl8-nSD-taF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812df2cb-100c-4a09-db8b-3969e0eba7e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='02a740cc-0eab-4d19-8ded-641ae8df7b4c'),\n",
              "  AIMessage(content=\"I can help with that! Could you provide more details about the specific issues you're facing with the API responses? For example, are you having trouble with parsing the response, handling errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 89, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C4ou32ZHs7anUPVu2sWZNMuNZ6hNa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--701a7af0-1d6b-44ad-9611-ba383a3b30cb-0', usage_metadata={'input_tokens': 89, 'output_tokens': 41, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='4991428d-d8ab-424d-bf28-5baf3076c088'),\n",
              "  AIMessage(content=\"You mentioned that you are working on a Python project and are stuck with handling API responses. If you provide more details about the specific issues you're encountering, I can help you better.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 145, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4ourLWpH1OLf9whWVsUlyfH0OBFG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b7a59240-6eaf-43db-9a41-488cb0112d73-0', usage_metadata={'input_tokens': 145, 'output_tokens': 36, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "chatbot_graph.invoke({\"messages\": [HumanMessage(content=\"Sorry what was my previous question?\")]}, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mNQWgbBE-taF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32a7a27-c82a-4603-ada6-4db0a9fe857e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='02a740cc-0eab-4d19-8ded-641ae8df7b4c'),\n",
              "  AIMessage(content=\"I can help with that! Could you provide more details about the specific issues you're facing with the API responses? For example, are you having trouble with parsing the response, handling errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 89, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C4ou32ZHs7anUPVu2sWZNMuNZ6hNa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--701a7af0-1d6b-44ad-9611-ba383a3b30cb-0', usage_metadata={'input_tokens': 89, 'output_tokens': 41, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='4991428d-d8ab-424d-bf28-5baf3076c088'),\n",
              "  AIMessage(content=\"You mentioned that you are working on a Python project and are stuck with handling API responses. If you provide more details about the specific issues you're encountering, I can help you better.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 145, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4ourLWpH1OLf9whWVsUlyfH0OBFG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b7a59240-6eaf-43db-9a41-488cb0112d73-0', usage_metadata={'input_tokens': 145, 'output_tokens': 36, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='d73cffa0-8bbf-4674-bfbb-0a10ab4e948b'),\n",
              "  AIMessage(content='Parsing JSON responses can sometimes lead to issues, especially if the structure varies. Here are some tips to help you handle this better:\\n\\n1. **Check the Response Structure**: Before parsing, it\\'s a good idea to print the entire response or use `json.dumps()` to see the structure clearly.\\n\\n2. **Use Try-Except for Parsing**: Wrap your parsing logic in a try-except block to catch any KeyError or TypeError that might arise if the structure isn’t what you expected.\\n\\n   ```python\\n   import json\\n\\n   response = # your API response here\\n   try:\\n       data = json.loads(response)\\n       # proceed with accessing the data\\n   except json.JSONDecodeError:\\n       print(\"Failed to decode JSON\")\\n   except KeyError as e:\\n       print(f\"Key not found: {e}\")\\n   ```\\n\\n3. **Check for Optional Fields**: If certain fields may not always be present, consider using the `.get()` method when accessing dictionary keys:\\n\\n   ```python\\n   value = data.get(\\'key\\', default_value)  # Returns default_value if \\'key\\' doesn\\'t exist\\n   ```\\n\\n4. **Validate the Response**: Verify the response status code and content type to ensure that you are dealing with valid JSON.\\n\\n   ```python\\n   if response.status_code == 200:\\n       if response.headers[\\'Content-Type\\'] == \\'application/json\\':\\n           data = response.json()  # If using requests library\\n       else:\\n           print(\"Response is not JSON\")\\n   ```\\n\\n5. **Schema Validation**: For more complex APIs, consider using a library like `jsonschema` to validate the structure of your JSON against a schema.\\n\\nIf you encounter a specific JSON structure or error message, feel free to share it, and I can provide more targeted assistance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 367, 'prompt_tokens': 220, 'total_tokens': 587, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4ov4YzcRMC91gQfXkkaRQfWIDYt3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dd742918-f4e9-4805-bb76-7bc93f4b0ccd-0', usage_metadata={'input_tokens': 220, 'output_tokens': 367, 'total_tokens': 587, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "chatbot_graph.invoke({\"messages\": [HumanMessage(content=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\")]}, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iz_zxiKN-taG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f38f252-ff0b-440c-bbef-bb6289146b65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='02a740cc-0eab-4d19-8ded-641ae8df7b4c'),\n",
              "  AIMessage(content=\"I can help with that! Could you provide more details about the specific issues you're facing with the API responses? For example, are you having trouble with parsing the response, handling errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 89, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C4ou32ZHs7anUPVu2sWZNMuNZ6hNa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--701a7af0-1d6b-44ad-9611-ba383a3b30cb-0', usage_metadata={'input_tokens': 89, 'output_tokens': 41, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='4991428d-d8ab-424d-bf28-5baf3076c088'),\n",
              "  AIMessage(content=\"You mentioned that you are working on a Python project and are stuck with handling API responses. If you provide more details about the specific issues you're encountering, I can help you better.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 145, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4ourLWpH1OLf9whWVsUlyfH0OBFG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b7a59240-6eaf-43db-9a41-488cb0112d73-0', usage_metadata={'input_tokens': 145, 'output_tokens': 36, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='d73cffa0-8bbf-4674-bfbb-0a10ab4e948b'),\n",
              "  AIMessage(content='Parsing JSON responses can sometimes lead to issues, especially if the structure varies. Here are some tips to help you handle this better:\\n\\n1. **Check the Response Structure**: Before parsing, it\\'s a good idea to print the entire response or use `json.dumps()` to see the structure clearly.\\n\\n2. **Use Try-Except for Parsing**: Wrap your parsing logic in a try-except block to catch any KeyError or TypeError that might arise if the structure isn’t what you expected.\\n\\n   ```python\\n   import json\\n\\n   response = # your API response here\\n   try:\\n       data = json.loads(response)\\n       # proceed with accessing the data\\n   except json.JSONDecodeError:\\n       print(\"Failed to decode JSON\")\\n   except KeyError as e:\\n       print(f\"Key not found: {e}\")\\n   ```\\n\\n3. **Check for Optional Fields**: If certain fields may not always be present, consider using the `.get()` method when accessing dictionary keys:\\n\\n   ```python\\n   value = data.get(\\'key\\', default_value)  # Returns default_value if \\'key\\' doesn\\'t exist\\n   ```\\n\\n4. **Validate the Response**: Verify the response status code and content type to ensure that you are dealing with valid JSON.\\n\\n   ```python\\n   if response.status_code == 200:\\n       if response.headers[\\'Content-Type\\'] == \\'application/json\\':\\n           data = response.json()  # If using requests library\\n       else:\\n           print(\"Response is not JSON\")\\n   ```\\n\\n5. **Schema Validation**: For more complex APIs, consider using a library like `jsonschema` to validate the structure of your JSON against a schema.\\n\\nIf you encounter a specific JSON structure or error message, feel free to share it, and I can provide more targeted assistance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 367, 'prompt_tokens': 220, 'total_tokens': 587, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4ov4YzcRMC91gQfXkkaRQfWIDYt3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dd742918-f4e9-4805-bb76-7bc93f4b0ccd-0', usage_metadata={'input_tokens': 220, 'output_tokens': 367, 'total_tokens': 587, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?', additional_kwargs={}, response_metadata={}, id='ac0b39b5-7a39-476c-b971-863a02c375a1'),\n",
              "  AIMessage(content=\"When dealing with deeply nested JSON data, especially when you only need a few specific values, here are some strategies to simplify the process:\\n\\n1. **Direct Access**: If the structure is consistent and you know the exact path to the values you need, you can access them directly:\\n\\n   ```python\\n   value = data['level1']['level2']['key']  # Accessing nested value directly\\n   ```\\n\\n2. **Using `.get()` Method**: For safer access, especially if some keys may not be present, use the `.get()` method:\\n\\n   ```python\\n   value = data.get('level1', {}).get('level2', {}).get('key', default_value)\\n   ```\\n\\n3. **List Comprehensions or Loops**: If you need to extract values from lists nested within the JSON, use list comprehensions:\\n\\n   ```python\\n   values = [item['key'] for item in data['level1']['items'] if 'key' in item]\\n   ```\\n\\n4. **Functions for Extraction**: You can define a function to encapsulate the extraction logic, which can improve readability:\\n\\n   ```python\\n   def get_nested_value(data, *keys):\\n       for key in keys:\\n           data = data.get(key, {})\\n           if not data:\\n               return None  # If any key is not found\\n       return data\\n\\n   value = get_nested_value(data, 'level1', 'level2', 'key')\\n   ```\\n\\n5. **JSONPath**: For very complex nested structures, consider using a library like `jsonpath-ng`, which allows you to query JSON data similarly to XPath for XML:\\n\\n   ```python\\n   from jsonpath_ng import jsonpath, parse\\n\\n   jsonpath_expr = parse('$.level1.level2.key')\\n   match = jsonpath_expr.find(data)\\n   values = [m.value for m in match]  # Extract matched values\\n   ```\\n\\n6. **Flattening the JSON**: If your JSON data is very complex, you might also consider flattening it into a simpler structure if possible. This can be especially useful for data analysis.\\n\\nBy employing these strategies, you can efficiently handle deeply nested JSON structures and extract only the values you need without getting overwhelmed by unnecessary data. If you have a specific JSON example you're working with, feel free to share it for more tailored advice!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 624, 'total_tokens': 1109, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4ovW6x5UuWek0YCbKX4P6vgIMl7a', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--34973263-5010-45ea-a582-3100347aaafe-0', usage_metadata={'input_tokens': 624, 'output_tokens': 485, 'total_tokens': 1109, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "chatbot_graph.invoke({\"messages\": [HumanMessage(content=\"Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?\")]}, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I8lNBJB-taG"
      },
      "source": [
        "# Defining your own schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dt5RGi13-taH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "98447a45-2539-4375-90c0-143e92020cff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# OPENAI_API_KEY environment variable must be set\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Defining Schema\n",
        "##################################################################################\n",
        "class State(MessagesState):\n",
        "    question: str\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Defining Agent's node\n",
        "##################################################################################\n",
        "\n",
        "# System message\n",
        "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
        "You are a helpful and knowledgeable chatbot assistant.\n",
        "Your goal is to provide clear and accurate answers to user questions based on the information they provide.\n",
        "Stay focused, concise, and ensure your responses are relevant to the context of the conversation.\n",
        "If you don’t have enough information, ask for clarification.”\n",
        "\"\"\"))\n",
        "\n",
        "# Node\n",
        "def chatbot(state: State) -> State:\n",
        "    question = HumanMessage(content=state.get(\"question\", \"\"))\n",
        "    response = llm.invoke([chatbot_system_message] + state[\"messages\"] + [question]);\n",
        "\n",
        "    return State(\n",
        "        messages = [question, response],\n",
        "        question = state.get(\"question\", None),\n",
        "        answer = response.content\n",
        "    )\n",
        "\n",
        "\n",
        "# Defining Graph\n",
        "##################################################################################\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "chatbot_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Show\n",
        "display(Image(chatbot_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "39SnduQ_-taH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d63bf2-f4df-40e0-f42e-c40efe5a31b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='6df4ed60-af43-4348-81c8-daf301d8efa4'),\n",
              "  AIMessage(content='I’d be happy to help! Could you provide more details about what specific issues you’re encountering with handling API responses? Are you having trouble making the request, parsing the response, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 89, 'total_tokens': 129, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxbBpaZ7osrygYhRHoxlm8DYC74', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--75a519aa-98c1-42c4-aef7-ae3f79d49252-0', usage_metadata={'input_tokens': 89, 'output_tokens': 40, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
              " 'answer': 'I’d be happy to help! Could you provide more details about what specific issues you’re encountering with handling API responses? Are you having trouble making the request, parsing the response, or something else?'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "thread_id = \"2\"\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "chatbot_graph.invoke(State(question=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2Y-L8CBS-taI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d697b9-e727-456f-ac91-29d944748725"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='6df4ed60-af43-4348-81c8-daf301d8efa4'),\n",
              "  AIMessage(content='I’d be happy to help! Could you provide more details about what specific issues you’re encountering with handling API responses? Are you having trouble making the request, parsing the response, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 89, 'total_tokens': 129, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxbBpaZ7osrygYhRHoxlm8DYC74', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--75a519aa-98c1-42c4-aef7-ae3f79d49252-0', usage_metadata={'input_tokens': 89, 'output_tokens': 40, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='22edafd1-9dc9-4483-9d5d-eb72b1db532a'),\n",
              "  AIMessage(content=\"You mentioned that you’re working on a Python project and are stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 144, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxhQ9rfkIYNhNaCYLnTJ57hOByL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8f5267b6-3d4c-4fc7-adad-a971a5a4e10e-0', usage_metadata={'input_tokens': 144, 'output_tokens': 30, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Sorry what was my previous question?',\n",
              " 'answer': \"You mentioned that you’re working on a Python project and are stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Sorry what was my previous question?\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BEpsGSM2-taI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9545f0ed-41b7-4bca-a2ac-8c4169103fe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='6df4ed60-af43-4348-81c8-daf301d8efa4'),\n",
              "  AIMessage(content='I’d be happy to help! Could you provide more details about what specific issues you’re encountering with handling API responses? Are you having trouble making the request, parsing the response, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 89, 'total_tokens': 129, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxbBpaZ7osrygYhRHoxlm8DYC74', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--75a519aa-98c1-42c4-aef7-ae3f79d49252-0', usage_metadata={'input_tokens': 89, 'output_tokens': 40, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='22edafd1-9dc9-4483-9d5d-eb72b1db532a'),\n",
              "  AIMessage(content=\"You mentioned that you’re working on a Python project and are stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 144, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxhQ9rfkIYNhNaCYLnTJ57hOByL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8f5267b6-3d4c-4fc7-adad-a971a5a4e10e-0', usage_metadata={'input_tokens': 144, 'output_tokens': 30, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='6c2e74cf-fe1e-41c7-b09f-a51372822429'),\n",
              "  AIMessage(content='Parsing JSON responses can indeed be tricky if the structure varies. Here are some tips to help you handle these situations more effectively:\\n\\n1. **Use `try` and `except` Blocks**: Wrap your parsing logic in a `try` block to handle exceptions if the JSON structure is not as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       # Access your data here\\n   except json.JSONDecodeError:\\n       print(\"Failed to parse JSON\")\\n   ```\\n\\n2. **Check for Keys Before Accessing**: Use `dict.get()` method which allows you to specify a default value if the key doesn’t exist.\\n\\n   ```python\\n   value = data.get(\\'expected_key\\', \\'default_value\\')\\n   ```\\n\\n3. **Validate the Structure**: Before accessing nested data, check if the keys and their expected types exist. \\n\\n   ```python\\n   if \\'key1\\' in data and isinstance(data[\\'key1\\'], dict):\\n       nested_value = data[\\'key1\\'].get(\\'nested_key\\', \\'default_value\\')\\n   ```\\n\\n4. **Logging for Structure Debugging**: If you\\'re unsure about the structure, print the entire response or use logging to see the full data received.\\n\\n   ```python\\n   print(json.dumps(data, indent=2))  # Pretty print the JSON response\\n   ```\\n\\n5. **Using JSON Schema**: Consider defining a JSON schema to validate the response if you\\'re dealing with a known structure.\\n\\n6. **Handling Lists**: If the response may include lists, ensure to check if you\\'re dealing with a list type before iterating.\\n\\n   ```python\\n   if isinstance(data.get(\\'list_key\\'), list):\\n       for item in data[\\'list_key\\']:\\n           # Process each item\\n   ```\\n\\nIf you have a specific JSON response causing issues, feel free to share, and I can provide more tailored guidance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 402, 'prompt_tokens': 213, 'total_tokens': 615, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxkaEEDEDcrFnYodm3PUMc1TtIE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--806e0b96-d42b-436a-9569-653aa4c5c302-0', usage_metadata={'input_tokens': 213, 'output_tokens': 402, 'total_tokens': 615, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
              " 'answer': 'Parsing JSON responses can indeed be tricky if the structure varies. Here are some tips to help you handle these situations more effectively:\\n\\n1. **Use `try` and `except` Blocks**: Wrap your parsing logic in a `try` block to handle exceptions if the JSON structure is not as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       # Access your data here\\n   except json.JSONDecodeError:\\n       print(\"Failed to parse JSON\")\\n   ```\\n\\n2. **Check for Keys Before Accessing**: Use `dict.get()` method which allows you to specify a default value if the key doesn’t exist.\\n\\n   ```python\\n   value = data.get(\\'expected_key\\', \\'default_value\\')\\n   ```\\n\\n3. **Validate the Structure**: Before accessing nested data, check if the keys and their expected types exist. \\n\\n   ```python\\n   if \\'key1\\' in data and isinstance(data[\\'key1\\'], dict):\\n       nested_value = data[\\'key1\\'].get(\\'nested_key\\', \\'default_value\\')\\n   ```\\n\\n4. **Logging for Structure Debugging**: If you\\'re unsure about the structure, print the entire response or use logging to see the full data received.\\n\\n   ```python\\n   print(json.dumps(data, indent=2))  # Pretty print the JSON response\\n   ```\\n\\n5. **Using JSON Schema**: Consider defining a JSON schema to validate the response if you\\'re dealing with a known structure.\\n\\n6. **Handling Lists**: If the response may include lists, ensure to check if you\\'re dealing with a list type before iterating.\\n\\n   ```python\\n   if isinstance(data.get(\\'list_key\\'), list):\\n       for item in data[\\'list_key\\']:\\n           # Process each item\\n   ```\\n\\nIf you have a specific JSON response causing issues, feel free to share, and I can provide more tailored guidance!'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tGf8vLys-taI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36edfd59-fb26-42e5-e381-d4bcc1eafc0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='6df4ed60-af43-4348-81c8-daf301d8efa4'),\n",
              "  AIMessage(content='I’d be happy to help! Could you provide more details about what specific issues you’re encountering with handling API responses? Are you having trouble making the request, parsing the response, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 89, 'total_tokens': 129, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxbBpaZ7osrygYhRHoxlm8DYC74', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--75a519aa-98c1-42c4-aef7-ae3f79d49252-0', usage_metadata={'input_tokens': 89, 'output_tokens': 40, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='22edafd1-9dc9-4483-9d5d-eb72b1db532a'),\n",
              "  AIMessage(content=\"You mentioned that you’re working on a Python project and are stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 144, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxhQ9rfkIYNhNaCYLnTJ57hOByL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8f5267b6-3d4c-4fc7-adad-a971a5a4e10e-0', usage_metadata={'input_tokens': 144, 'output_tokens': 30, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='6c2e74cf-fe1e-41c7-b09f-a51372822429'),\n",
              "  AIMessage(content='Parsing JSON responses can indeed be tricky if the structure varies. Here are some tips to help you handle these situations more effectively:\\n\\n1. **Use `try` and `except` Blocks**: Wrap your parsing logic in a `try` block to handle exceptions if the JSON structure is not as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       # Access your data here\\n   except json.JSONDecodeError:\\n       print(\"Failed to parse JSON\")\\n   ```\\n\\n2. **Check for Keys Before Accessing**: Use `dict.get()` method which allows you to specify a default value if the key doesn’t exist.\\n\\n   ```python\\n   value = data.get(\\'expected_key\\', \\'default_value\\')\\n   ```\\n\\n3. **Validate the Structure**: Before accessing nested data, check if the keys and their expected types exist. \\n\\n   ```python\\n   if \\'key1\\' in data and isinstance(data[\\'key1\\'], dict):\\n       nested_value = data[\\'key1\\'].get(\\'nested_key\\', \\'default_value\\')\\n   ```\\n\\n4. **Logging for Structure Debugging**: If you\\'re unsure about the structure, print the entire response or use logging to see the full data received.\\n\\n   ```python\\n   print(json.dumps(data, indent=2))  # Pretty print the JSON response\\n   ```\\n\\n5. **Using JSON Schema**: Consider defining a JSON schema to validate the response if you\\'re dealing with a known structure.\\n\\n6. **Handling Lists**: If the response may include lists, ensure to check if you\\'re dealing with a list type before iterating.\\n\\n   ```python\\n   if isinstance(data.get(\\'list_key\\'), list):\\n       for item in data[\\'list_key\\']:\\n           # Process each item\\n   ```\\n\\nIf you have a specific JSON response causing issues, feel free to share, and I can provide more tailored guidance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 402, 'prompt_tokens': 213, 'total_tokens': 615, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxkaEEDEDcrFnYodm3PUMc1TtIE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--806e0b96-d42b-436a-9569-653aa4c5c302-0', usage_metadata={'input_tokens': 213, 'output_tokens': 402, 'total_tokens': 615, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?', additional_kwargs={}, response_metadata={}, id='aed7ac1c-fc03-42db-a879-afb753e6edba'),\n",
              "  AIMessage(content=\"When dealing with deeply nested JSON data and you only need a few specific values, here are some strategies to effectively access those values while keeping your code clean and robust:\\n\\n1. **Use Helper Functions**: Create functions to centralize the logic for accessing specific nested values. This improves readability and reusability.\\n\\n   ```python\\n   def get_nested_value(data, keys, default=None):\\n       for key in keys:\\n           if isinstance(data, dict) and key in data:\\n               data = data[key]\\n           else:\\n               return default\\n       return data\\n\\n   # Usage\\n   value = get_nested_value(data, ['level1', 'level2', 'target_key'], 'default_value')\\n   ```\\n\\n2. **Avoid Deep Nesting in Access**: Store the required values in variables soon after parsing. This helps avoid repetitive and error-prone deep indexing.\\n\\n   ```python\\n   level1 = data.get('level1', {})\\n   level2 = level1.get('level2', {})\\n   target_value = level2.get('target_key', 'default_value')\\n   ```\\n\\n3. **Use List Comprehensions for Lists**: If you're extracting values from a list nested within your JSON, consider using list comprehensions for concise extraction.\\n\\n   ```python\\n   values = [item.get('target_key', 'default_value') for item in data.get('list_key', [])]\\n   ```\\n\\n4. **JSONPath Library**: If you find yourself needing to extract specific values regularly from various JSON structures, consider using a library like `jsonpath-ng`, which allows you to use a JSONPath query language.\\n\\n   ```python\\n   from jsonpath_ng import jsonpath, parse\\n\\n   jsonpath_expr = parse('$.level1.level2.target_key')\\n   match = jsonpath_expr.find(data)\\n   target_value = match[0].value if match else 'default_value'\\n   ```\\n\\n5. **Keep It Simple**: Only navigate through levels of the JSON structure that are necessary. If the structure is complex, think about whether you can simplify it by re-structuring it on the server side or using aggregation to return only the needed values.\\n\\nBy using these strategies, you can make your code more maintainable and reduce the likelihood of errors when handling deeply nested JSON data. If you'd like, I can help with a specific example if you share the JSON structure you're working with!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 488, 'prompt_tokens': 652, 'total_tokens': 1140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oxsEQbnYyzDAktgTvwZfd06bfo6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--da9a8416-a877-4034-b434-ae9e61b3f94d-0', usage_metadata={'input_tokens': 652, 'output_tokens': 488, 'total_tokens': 1140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?',\n",
              " 'answer': \"When dealing with deeply nested JSON data and you only need a few specific values, here are some strategies to effectively access those values while keeping your code clean and robust:\\n\\n1. **Use Helper Functions**: Create functions to centralize the logic for accessing specific nested values. This improves readability and reusability.\\n\\n   ```python\\n   def get_nested_value(data, keys, default=None):\\n       for key in keys:\\n           if isinstance(data, dict) and key in data:\\n               data = data[key]\\n           else:\\n               return default\\n       return data\\n\\n   # Usage\\n   value = get_nested_value(data, ['level1', 'level2', 'target_key'], 'default_value')\\n   ```\\n\\n2. **Avoid Deep Nesting in Access**: Store the required values in variables soon after parsing. This helps avoid repetitive and error-prone deep indexing.\\n\\n   ```python\\n   level1 = data.get('level1', {})\\n   level2 = level1.get('level2', {})\\n   target_value = level2.get('target_key', 'default_value')\\n   ```\\n\\n3. **Use List Comprehensions for Lists**: If you're extracting values from a list nested within your JSON, consider using list comprehensions for concise extraction.\\n\\n   ```python\\n   values = [item.get('target_key', 'default_value') for item in data.get('list_key', [])]\\n   ```\\n\\n4. **JSONPath Library**: If you find yourself needing to extract specific values regularly from various JSON structures, consider using a library like `jsonpath-ng`, which allows you to use a JSONPath query language.\\n\\n   ```python\\n   from jsonpath_ng import jsonpath, parse\\n\\n   jsonpath_expr = parse('$.level1.level2.target_key')\\n   match = jsonpath_expr.find(data)\\n   target_value = match[0].value if match else 'default_value'\\n   ```\\n\\n5. **Keep It Simple**: Only navigate through levels of the JSON structure that are necessary. If the structure is complex, think about whether you can simplify it by re-structuring it on the server side or using aggregation to return only the needed values.\\n\\nBy using these strategies, you can make your code more maintainable and reduce the likelihood of errors when handling deeply nested JSON data. If you'd like, I can help with a specific example if you share the JSON structure you're working with!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?\"), config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVHisdqm-taI"
      },
      "source": [
        "# Message Shrinking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTEW6bRo-taI"
      },
      "source": [
        "## Limit number of messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KmOzXX4d-taI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "235ba174-5a47-4bc0-e0fe-1dd0ca876ae4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# OPENAI_API_KEY environment variable must be set\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Defining Schema\n",
        "##################################################################################\n",
        "class State(MessagesState):\n",
        "    question: str\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Defining Agent's node\n",
        "##################################################################################\n",
        "\n",
        "# System message\n",
        "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
        "You are a helpful and knowledgeable chatbot assistant.\n",
        "Your goal is to provide clear and accurate answers to user questions based on the information they provide.\n",
        "Stay focused, concise, and ensure your responses are relevant to the context of the conversation.\n",
        "If you don’t have enough information, ask for clarification.”\n",
        "\"\"\"))\n",
        "\n",
        "# Node\n",
        "def chatbot(state: State) -> State:\n",
        "    question = HumanMessage(content=state.get(\"question\", \"\"))\n",
        "\n",
        "    trimed_messages = (state[\"messages\"] + [question])[-4:]\n",
        "    print(f\"Messages sent to LLM: {len(trimed_messages)}\")\n",
        "\n",
        "    response = llm.invoke([chatbot_system_message] + trimed_messages);\n",
        "\n",
        "    return State(\n",
        "        messages = [question, response],\n",
        "        question = state.get(\"question\", None),\n",
        "        answer = response.content\n",
        "    )\n",
        "\n",
        "\n",
        "# Defining Graph\n",
        "##################################################################################\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "chatbot_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Show\n",
        "display(Image(chatbot_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZRryY2rr-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55fbfe5f-43d6-4d6f-e81c-8aaa10572f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='be417f7d-0173-4526-92ff-a27d8732ff9f'),\n",
              "  AIMessage(content=\"I'd be happy to help! Could you provide more details on the specific issues you're facing with handling API responses in your Python project? Are you having trouble with parsing the response, managing errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 89, 'total_tokens': 131, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oylEOC5TQvFIH7lwYIc59jcpQdr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--19421f29-aeb0-4e26-b698-3b86fc462b31-0', usage_metadata={'input_tokens': 89, 'output_tokens': 42, 'total_tokens': 131, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
              " 'answer': \"I'd be happy to help! Could you provide more details on the specific issues you're facing with handling API responses in your Python project? Are you having trouble with parsing the response, managing errors, or something else?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "thread_id = \"1\"\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "chatbot_graph.invoke(State(question=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dF0lk4k6-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949dcd70-298e-4386-a0cb-41e8438d5b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='be417f7d-0173-4526-92ff-a27d8732ff9f'),\n",
              "  AIMessage(content=\"I'd be happy to help! Could you provide more details on the specific issues you're facing with handling API responses in your Python project? Are you having trouble with parsing the response, managing errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 89, 'total_tokens': 131, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oylEOC5TQvFIH7lwYIc59jcpQdr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--19421f29-aeb0-4e26-b698-3b86fc462b31-0', usage_metadata={'input_tokens': 89, 'output_tokens': 42, 'total_tokens': 131, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='057e2660-8dca-45f9-9be0-846042ca3d87'),\n",
              "  AIMessage(content=\"You mentioned that you're working on a Python project and that you're stuck with handling API responses. If you have any specific questions or issues, feel free to share, and I'll do my best to assist you!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 146, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oyo9M9CluD5PtwrA0IBKBSh9MZH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--43d2c0ba-f5b1-4f57-a497-27314792d98b-0', usage_metadata={'input_tokens': 146, 'output_tokens': 41, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Sorry what was my previous question?',\n",
              " 'answer': \"You mentioned that you're working on a Python project and that you're stuck with handling API responses. If you have any specific questions or issues, feel free to share, and I'll do my best to assist you!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Sorry what was my previous question?\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JsJBAv2H-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c897fea-e1ac-4f3d-876b-b4f3311dc431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='be417f7d-0173-4526-92ff-a27d8732ff9f'),\n",
              "  AIMessage(content=\"I'd be happy to help! Could you provide more details on the specific issues you're facing with handling API responses in your Python project? Are you having trouble with parsing the response, managing errors, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 89, 'total_tokens': 131, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oylEOC5TQvFIH7lwYIc59jcpQdr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--19421f29-aeb0-4e26-b698-3b86fc462b31-0', usage_metadata={'input_tokens': 89, 'output_tokens': 42, 'total_tokens': 131, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='057e2660-8dca-45f9-9be0-846042ca3d87'),\n",
              "  AIMessage(content=\"You mentioned that you're working on a Python project and that you're stuck with handling API responses. If you have any specific questions or issues, feel free to share, and I'll do my best to assist you!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 146, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4oyo9M9CluD5PtwrA0IBKBSh9MZH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--43d2c0ba-f5b1-4f57-a497-27314792d98b-0', usage_metadata={'input_tokens': 146, 'output_tokens': 41, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='21066ba7-a111-460f-90cb-f0585adc5c5d'),\n",
              "  AIMessage(content='Parsing JSON responses can indeed be tricky if the structure varies. Here are a few tips to help you handle this more effectively:\\n\\n1. **Use Try-Except for Error Handling**: Wrap your JSON parsing code in a try-except block to catch any errors that might occur if the structure isn\\'t as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n\\n   try:\\n       data = json.loads(response)\\n       # Access specific fields\\n   except json.JSONDecodeError:\\n       print(\"Failed to parse JSON\")\\n   ```\\n\\n2. **Check for Keys with `.get()`**: Use the `.get()` method when accessing dictionary keys. This way, you can avoid `KeyError` exceptions if a key is missing.\\n\\n   ```python\\n   value = data.get(\\'key\\', \\'default_value\\')  # \\'default_value\\' if \\'key\\' doesn\\'t exist\\n   ```\\n\\n3. **Validate the Structure**: If the structure of the JSON varies, consider validating it before accessing data. Libraries like `jsonschema` can be used to validate against a schema.\\n\\n4. **Use Default Values**: Provide default values for missing keys or unexpected structures to keep your code from breaking.\\n\\n5. **Inspect the Response**: If you\\'re not sure of the structure, use `print()` or logging to inspect the entire response to understand its format better.\\n\\nIf you have a specific example of a JSON response you\\'re struggling with, feel free to share it, and I can provide more tailored guidance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 314, 'prompt_tokens': 203, 'total_tokens': 517, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-C4p1wJMQiQoQ7FTAuUiTH9kAv7ejE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--af758707-db37-40d6-b2b3-92a0e7a51cb3-0', usage_metadata={'input_tokens': 203, 'output_tokens': 314, 'total_tokens': 517, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
              " 'answer': 'Parsing JSON responses can indeed be tricky if the structure varies. Here are a few tips to help you handle this more effectively:\\n\\n1. **Use Try-Except for Error Handling**: Wrap your JSON parsing code in a try-except block to catch any errors that might occur if the structure isn\\'t as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n\\n   try:\\n       data = json.loads(response)\\n       # Access specific fields\\n   except json.JSONDecodeError:\\n       print(\"Failed to parse JSON\")\\n   ```\\n\\n2. **Check for Keys with `.get()`**: Use the `.get()` method when accessing dictionary keys. This way, you can avoid `KeyError` exceptions if a key is missing.\\n\\n   ```python\\n   value = data.get(\\'key\\', \\'default_value\\')  # \\'default_value\\' if \\'key\\' doesn\\'t exist\\n   ```\\n\\n3. **Validate the Structure**: If the structure of the JSON varies, consider validating it before accessing data. Libraries like `jsonschema` can be used to validate against a schema.\\n\\n4. **Use Default Values**: Provide default values for missing keys or unexpected structures to keep your code from breaking.\\n\\n5. **Inspect the Response**: If you\\'re not sure of the structure, use `print()` or logging to inspect the entire response to understand its format better.\\n\\nIf you have a specific example of a JSON response you\\'re struggling with, feel free to share it, and I can provide more tailored guidance!'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\"), config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uyTex1q-taJ"
      },
      "source": [
        "## Trim messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eYUAoPOT-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "955b88a7-761e-4136-dac4-0285742679d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.messages import trim_messages\n",
        "\n",
        "# OPENAI_API_KEY environment variable must be set\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Defining Schema\n",
        "##################################################################################\n",
        "class State(MessagesState):\n",
        "    question: str\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Defining Agent's node\n",
        "##################################################################################\n",
        "\n",
        "# System message\n",
        "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
        "You are a helpful and knowledgeable chatbot assistant.\n",
        "Your goal is to provide clear and accurate answers to user questions based on the information they provide.\n",
        "Stay focused, concise, and ensure your responses are relevant to the context of the conversation.\n",
        "If you don’t have enough information, ask for clarification.”\n",
        "\"\"\"))\n",
        "\n",
        "# Node\n",
        "def chatbot(state: State) -> State:\n",
        "    question = HumanMessage(content=state.get(\"question\", \"\"))\n",
        "\n",
        "    trimed_messages = trim_messages(\n",
        "            state[\"messages\"] + [question],\n",
        "            max_tokens=200,                # keep 4-5 messages including longer detailed responses\n",
        "            strategy=\"last\",                # keep the most recent\n",
        "            token_counter=llm,              # the model used to count tokens\n",
        "            allow_partial=False             # only include complete messages (preserve message integrity)\n",
        "        )\n",
        "    print(f\"Messages sent to LLM: {len(trimed_messages)}\")\n",
        "\n",
        "    response = llm.invoke([chatbot_system_message] + trimed_messages);\n",
        "\n",
        "    return State(\n",
        "        messages = [question, response],\n",
        "        question = state.get(\"question\", None),\n",
        "        answer = response.content\n",
        "    )\n",
        "\n",
        "\n",
        "# Defining Graph\n",
        "##################################################################################\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "chatbot_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Show\n",
        "display(Image(chatbot_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VtOhc8uj-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589d10cb-bf9f-438d-db82-0bd307753bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='bfc5d463-aea8-4869-bd86-f029f74ac812'),\n",
              "  AIMessage(content='Sure, I can help with that! Could you provide more details about the API you’re working with and the specific issues you’re encountering with handling the responses?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 89, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p56VxJnmndWvPREXyKLEZ6JyUky', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6627d7dd-9fd3-431f-adf0-6e9ee659f646-0', usage_metadata={'input_tokens': 89, 'output_tokens': 32, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
              " 'answer': 'Sure, I can help with that! Could you provide more details about the API you’re working with and the specific issues you’re encountering with handling the responses?'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "thread_id = \"3\"\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "chatbot_graph.invoke(State(question=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fHXU1mTo-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b716d338-810b-4cc9-f2cb-f85e32c1b2dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='bfc5d463-aea8-4869-bd86-f029f74ac812'),\n",
              "  AIMessage(content='Sure, I can help with that! Could you provide more details about the API you’re working with and the specific issues you’re encountering with handling the responses?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 89, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p56VxJnmndWvPREXyKLEZ6JyUky', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6627d7dd-9fd3-431f-adf0-6e9ee659f646-0', usage_metadata={'input_tokens': 89, 'output_tokens': 32, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='0a05640b-b191-4417-8648-cff2c0600f6e'),\n",
              "  AIMessage(content=\"You mentioned that you were working on a Python project and were stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 136, 'total_tokens': 166, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p5COraJQCda8E1DI1wMCWG6QDxE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e6859dc-6083-479e-b826-dc917b0bdc7c-0', usage_metadata={'input_tokens': 136, 'output_tokens': 30, 'total_tokens': 166, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Sorry what was my previous question?',\n",
              " 'answer': \"You mentioned that you were working on a Python project and were stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Sorry what was my previous question?\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dTjIsNT6-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58def9ae-1ad6-47cf-a301-e80161475ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='bfc5d463-aea8-4869-bd86-f029f74ac812'),\n",
              "  AIMessage(content='Sure, I can help with that! Could you provide more details about the API you’re working with and the specific issues you’re encountering with handling the responses?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 89, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p56VxJnmndWvPREXyKLEZ6JyUky', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6627d7dd-9fd3-431f-adf0-6e9ee659f646-0', usage_metadata={'input_tokens': 89, 'output_tokens': 32, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='0a05640b-b191-4417-8648-cff2c0600f6e'),\n",
              "  AIMessage(content=\"You mentioned that you were working on a Python project and were stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 136, 'total_tokens': 166, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p5COraJQCda8E1DI1wMCWG6QDxE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e6859dc-6083-479e-b826-dc917b0bdc7c-0', usage_metadata={'input_tokens': 136, 'output_tokens': 30, 'total_tokens': 166, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='333fc187-5368-41ae-8980-e2df3a72be49'),\n",
              "  AIMessage(content='Parsing JSON can sometimes be tricky if the structure varies. Here are some tips to handle unexpected JSON structures in Python:\\n\\n1. **Use a Try-Except Block**: Wrap your parsing logic in a try-except block to catch errors when the structure doesn’t match your expectations.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example JSON string\\n   try:\\n       data = json.loads(response)\\n       # Access the data, e.g., data[\\'key\\']\\n   except KeyError as e:\\n       print(f\"Key error: {e}\")\\n   except json.JSONDecodeError:\\n       print(\"Could not decode JSON.\")\\n   ```\\n\\n2. **Check for Keys**: Before accessing a key, check if it exists using the `in` keyword or the `get()` method, which returns `None` if the key does not exist.\\n\\n   ```python\\n   if \\'expected_key\\' in data:\\n       value = data[\\'expected_key\\']\\n   else:\\n       print(\"Key not found.\")\\n   ```\\n\\n   or \\n\\n   ```python\\n   value = data.get(\\'expected_key\\', \\'default_value\\')\\n   ```\\n\\n3. **Use Default Values**: Provide default values when accessing keys that may or may not be present.\\n\\n4. **Debugging with Print Statements**: Before processing, print the entire response or parts of it to better understand its structure.\\n\\n5. **Use a Data Validation Library**: Consider using libraries like `pydantic` or `marshmallow` to validate and parse JSON data more robustly.\\n\\n6. **Logging**: Instead of printing errors, use a logging library to log issues for future analysis.\\n\\nIf you can share an example of the JSON response that\\'s causing the issue or what you\\'re trying to extract, I can provide more specific guidance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 205, 'total_tokens': 576, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p5FXu0Kk5jR9zABuxbFwWXteP1J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4400f714-1e1b-4c64-8a77-1f87f2802d77-0', usage_metadata={'input_tokens': 205, 'output_tokens': 371, 'total_tokens': 576, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
              " 'answer': 'Parsing JSON can sometimes be tricky if the structure varies. Here are some tips to handle unexpected JSON structures in Python:\\n\\n1. **Use a Try-Except Block**: Wrap your parsing logic in a try-except block to catch errors when the structure doesn’t match your expectations.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example JSON string\\n   try:\\n       data = json.loads(response)\\n       # Access the data, e.g., data[\\'key\\']\\n   except KeyError as e:\\n       print(f\"Key error: {e}\")\\n   except json.JSONDecodeError:\\n       print(\"Could not decode JSON.\")\\n   ```\\n\\n2. **Check for Keys**: Before accessing a key, check if it exists using the `in` keyword or the `get()` method, which returns `None` if the key does not exist.\\n\\n   ```python\\n   if \\'expected_key\\' in data:\\n       value = data[\\'expected_key\\']\\n   else:\\n       print(\"Key not found.\")\\n   ```\\n\\n   or \\n\\n   ```python\\n   value = data.get(\\'expected_key\\', \\'default_value\\')\\n   ```\\n\\n3. **Use Default Values**: Provide default values when accessing keys that may or may not be present.\\n\\n4. **Debugging with Print Statements**: Before processing, print the entire response or parts of it to better understand its structure.\\n\\n5. **Use a Data Validation Library**: Consider using libraries like `pydantic` or `marshmallow` to validate and parse JSON data more robustly.\\n\\n6. **Logging**: Instead of printing errors, use a logging library to log issues for future analysis.\\n\\nIf you can share an example of the JSON response that\\'s causing the issue or what you\\'re trying to extract, I can provide more specific guidance!'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WqFmp3Qt-taJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6539b5-1991-4c2d-e144-467f0960f106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages sent to LLM: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='bfc5d463-aea8-4869-bd86-f029f74ac812'),\n",
              "  AIMessage(content='Sure, I can help with that! Could you provide more details about the API you’re working with and the specific issues you’re encountering with handling the responses?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 89, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p56VxJnmndWvPREXyKLEZ6JyUky', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6627d7dd-9fd3-431f-adf0-6e9ee659f646-0', usage_metadata={'input_tokens': 89, 'output_tokens': 32, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='0a05640b-b191-4417-8648-cff2c0600f6e'),\n",
              "  AIMessage(content=\"You mentioned that you were working on a Python project and were stuck with handling API responses. Would you like to elaborate on the specific issue you're facing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 136, 'total_tokens': 166, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p5COraJQCda8E1DI1wMCWG6QDxE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e6859dc-6083-479e-b826-dc917b0bdc7c-0', usage_metadata={'input_tokens': 136, 'output_tokens': 30, 'total_tokens': 166, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='333fc187-5368-41ae-8980-e2df3a72be49'),\n",
              "  AIMessage(content='Parsing JSON can sometimes be tricky if the structure varies. Here are some tips to handle unexpected JSON structures in Python:\\n\\n1. **Use a Try-Except Block**: Wrap your parsing logic in a try-except block to catch errors when the structure doesn’t match your expectations.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example JSON string\\n   try:\\n       data = json.loads(response)\\n       # Access the data, e.g., data[\\'key\\']\\n   except KeyError as e:\\n       print(f\"Key error: {e}\")\\n   except json.JSONDecodeError:\\n       print(\"Could not decode JSON.\")\\n   ```\\n\\n2. **Check for Keys**: Before accessing a key, check if it exists using the `in` keyword or the `get()` method, which returns `None` if the key does not exist.\\n\\n   ```python\\n   if \\'expected_key\\' in data:\\n       value = data[\\'expected_key\\']\\n   else:\\n       print(\"Key not found.\")\\n   ```\\n\\n   or \\n\\n   ```python\\n   value = data.get(\\'expected_key\\', \\'default_value\\')\\n   ```\\n\\n3. **Use Default Values**: Provide default values when accessing keys that may or may not be present.\\n\\n4. **Debugging with Print Statements**: Before processing, print the entire response or parts of it to better understand its structure.\\n\\n5. **Use a Data Validation Library**: Consider using libraries like `pydantic` or `marshmallow` to validate and parse JSON data more robustly.\\n\\n6. **Logging**: Instead of printing errors, use a logging library to log issues for future analysis.\\n\\nIf you can share an example of the JSON response that\\'s causing the issue or what you\\'re trying to extract, I can provide more specific guidance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 205, 'total_tokens': 576, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p5FXu0Kk5jR9zABuxbFwWXteP1J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4400f714-1e1b-4c64-8a77-1f87f2802d77-0', usage_metadata={'input_tokens': 205, 'output_tokens': 371, 'total_tokens': 576, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?', additional_kwargs={}, response_metadata={}, id='2e601aba-22a1-4fe9-ba53-01f8631daea8'),\n",
              "  AIMessage(content=\"When dealing with deeply nested JSON data and you only need a few specific values, the best approach is to:\\n\\n1. **Use a JSON parsing library**: Depending on your programming language, use a library designed to parse JSON efficiently (e.g., `json` in Python, `json_decode` in PHP, or `JSON.parse` in JavaScript).\\n\\n2. **Access properties directly**: Once the JSON is parsed into an object, you can access nested properties using dot notation or bracket notation, depending on the language.\\n\\n3. **Destructure or map**: If applicable, use destructuring (in JavaScript) or mapping (in Python) to extract the specific values you need more succinctly.\\n\\n4. **Use a filtering function**: In more complex scenarios, consider writing a function that traverses the JSON structure and collects the values you need, especially if the structure varies.\\n\\n5. **Consider JSONPath**: If you're using a complex JSON structure and want to query specific values, you can use libraries that support JSONPath, enabling you to specify the path to the values you want to extract.\\n\\nIf you share the format of your JSON data and the specific values you're interested in, I can provide a more tailored example!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 99, 'total_tokens': 349, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4p5RqmUVEjYJEan6EHcTtiI449Jh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f2636d28-82f7-4f74-b91b-fa3d68767fe2-0', usage_metadata={'input_tokens': 99, 'output_tokens': 250, 'total_tokens': 349, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?',\n",
              " 'answer': \"When dealing with deeply nested JSON data and you only need a few specific values, the best approach is to:\\n\\n1. **Use a JSON parsing library**: Depending on your programming language, use a library designed to parse JSON efficiently (e.g., `json` in Python, `json_decode` in PHP, or `JSON.parse` in JavaScript).\\n\\n2. **Access properties directly**: Once the JSON is parsed into an object, you can access nested properties using dot notation or bracket notation, depending on the language.\\n\\n3. **Destructure or map**: If applicable, use destructuring (in JavaScript) or mapping (in Python) to extract the specific values you need more succinctly.\\n\\n4. **Use a filtering function**: In more complex scenarios, consider writing a function that traverses the JSON structure and collects the values you need, especially if the structure varies.\\n\\n5. **Consider JSONPath**: If you're using a complex JSON structure and want to query specific values, you can use libraries that support JSONPath, enabling you to specify the path to the values you want to extract.\\n\\nIf you share the format of your JSON data and the specific values you're interested in, I can provide a more tailored example!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "chatbot_graph.invoke(State(question=\"Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?\"), config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adfYR-dZ-taK"
      },
      "source": [
        "let's allow partial!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}