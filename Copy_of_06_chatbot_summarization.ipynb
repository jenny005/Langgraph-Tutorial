{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenny005/Langgraph-Tutorial/blob/main/Copy_of_06_chatbot_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY6PsaGG_v2n"
      },
      "source": [
        "# Messages Summarization\n",
        "![Chain](https://github.com/esurovtsev/langgraph-intro/blob/main/images/summarization.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Lmv6C4Mq_63y",
        "outputId": "314ffc38-5493-4c27-891f-a47ca010d059"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 1)) (4.14.1)\n",
            "Collecting typing (from -r /content/requirements.txt (line 2))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langgraph (from -r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph-0.6.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai (from -r /content/requirements.txt (line 4))\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 5)) (0.3.74)\n",
            "Collecting langgraph-checkpoint-mongodb (from -r /content/requirements.txt (line 6))\n",
            "  Downloading langgraph_checkpoint_mongodb-0.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community (from -r /content/requirements.txt (line 7))\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting python-dotenv (from -r /content/requirements.txt (line 8))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 9)) (0.2.65)\n",
            "Collecting pymongo (from -r /content/requirements.txt (line 10))\n",
            "  Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting wikipedia (from -r /content/requirements.txt (line 11))\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trustcall (from -r /content/requirements.txt (line 12))\n",
            "  Downloading trustcall-0.0.39-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting langchain-mcp-adapters (from -r /content/requirements.txt (line 13))\n",
            "  Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r /content/requirements.txt (line 3)) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r /content/requirements.txt (line 3)) (3.5.0)\n",
            "Collecting openai<2.0.0,>=1.99.9 (from langchain_openai->-r /content/requirements.txt (line 4))\n",
            "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->-r /content/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (25.0)\n",
            "Collecting langchain-mongodb>=0.6.1 (from langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading langchain_mongodb-0.6.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting motor>3.6.0 (from langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading motor-3.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pymongo (from -r /content/requirements.txt (line 10))\n",
            "  Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (15.0.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo->-r /content/requirements.txt (line 10))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting dydantic<1.0.0,>=0.0.8 (from trustcall->-r /content/requirements.txt (line 12))\n",
            "  Downloading dydantic-0.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting mcp>=1.9.2 (from langchain-mcp-adapters->-r /content/requirements.txt (line 13))\n",
            "  Downloading mcp-1.13.0-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.20.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r /content/requirements.txt (line 9)) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (2025.8.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r /content/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community->-r /content/requirements.txt (line 7)) (0.3.9)\n",
            "Collecting lark<2.0.0,>=1.1.9 (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core->-r /content/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core->-r /content/requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (4.25.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13))\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.47.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r /content/requirements.txt (line 7)) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai->-r /content/requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (2.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (8.2.1)\n",
            "Downloading langgraph-0.6.5-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint_mongodb-0.1.4-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trustcall-0.0.39-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dydantic-0.0.8-py3-none-any.whl (8.6 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langchain_mongodb-0.6.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.13.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.7.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: typing, wikipedia\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=e65704bc6d4d820564fac349fe7690e27522c973606e3444a7d7c776926eb757\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=b289b44dd78a02fce3fca13a0ca3e349df9b3d9152262f1158e154a2e699dc98\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built typing wikipedia\n",
            "Installing collected packages: typing, python-dotenv, ormsgpack, mypy-extensions, marshmallow, lark, httpx-sse, dnspython, wikipedia, typing-inspect, sse-starlette, pymongo, pydantic-settings, openai, motor, langgraph-sdk, dydantic, dataclasses-json, mcp, langgraph-checkpoint, langchain_openai, langchain-mcp-adapters, langgraph-prebuilt, langgraph, langchain-mongodb, langchain_community, trustcall, langgraph-checkpoint-mongodb\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.8\n",
            "    Uninstalling openai-1.99.8:\n",
            "      Successfully uninstalled openai-1.99.8\n",
            "Successfully installed dataclasses-json-0.6.7 dnspython-2.7.0 dydantic-0.0.8 httpx-sse-0.4.1 langchain-mcp-adapters-0.1.9 langchain-mongodb-0.6.2 langchain_community-0.3.27 langchain_openai-0.3.30 langgraph-0.6.5 langgraph-checkpoint-2.1.1 langgraph-checkpoint-mongodb-0.1.4 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 lark-1.2.2 marshmallow-3.26.1 mcp-1.13.0 motor-3.7.1 mypy-extensions-1.1.0 openai-1.99.9 ormsgpack-1.10.0 pydantic-settings-2.10.1 pymongo-4.12.1 python-dotenv-1.1.1 sse-starlette-3.0.2 trustcall-0.0.39 typing-3.7.4.3 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "3246ac76fee44b849f2dce550e110aa0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv  # load environment variables from a .env file into your program’s os.environ dictionary\n",
        "load_dotenv(\"/content/.env\", override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfflGQ_I_666",
        "outputId": "5c81d9f7-2796-40d1-86db-6c314c382c69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uybMn1fX_v2p"
      },
      "source": [
        "## \"Standard\" chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AoY-ODd3_v2q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "59a1a127-8f32-41d9-c6f4-910f68221f7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import START, END, StateGraph, MessagesState\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# OPENAI_API_KEY environment variable must be set\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Defining Schema\n",
        "##################################################################################\n",
        "class State(MessagesState):\n",
        "    question: str\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Defining Agent's node\n",
        "##################################################################################\n",
        "\n",
        "# System message\n",
        "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
        "You are a helpful and knowledgeable chatbot assistant.\n",
        "Your goal is to provide clear and accurate answers to user questions based on the information they provide.\n",
        "Stay focused, concise, and ensure your responses are relevant to the context of the conversation.\n",
        "If you don’t have enough information, ask for clarification.”\n",
        "\"\"\"))\n",
        "\n",
        "# Node\n",
        "def chatbot(state: State) -> State:\n",
        "    question = HumanMessage(content=state.get(\"question\", \"\"))\n",
        "    response = llm.invoke([chatbot_system_message] + state[\"messages\"] + [question]);\n",
        "\n",
        "    return State(\n",
        "        messages = [question, response],\n",
        "        question = state.get(\"question\", None),\n",
        "        answer = response.content\n",
        "    )\n",
        "\n",
        "\n",
        "# Defining Graph\n",
        "##################################################################################\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "chatbot_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Show\n",
        "display(Image(chatbot_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEkfsBQh_v2r"
      },
      "source": [
        "## Removing messages\n",
        "\n",
        "1) we use MessagesState\n",
        "2) MessageState has a built-in list of messages (\"messages\" key)\n",
        "3) Key \"messages\" has a built-in reducer \"add_messages\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4NkQADLq_v2r"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import AnyMessage\n",
        "\n",
        "class MessagesState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_GKUZokD_v2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b418f25b-064f-41c9-c6cf-8914fa5ac6cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Message 1', additional_kwargs={}, response_metadata={}, id='1'),\n",
              " AIMessage(content='Message 2', additional_kwargs={}, response_metadata={}, id='2'),\n",
              " HumanMessage(content='Message 3', additional_kwargs={}, response_metadata={}, id='3'),\n",
              " AIMessage(content='Message 4', additional_kwargs={}, response_metadata={}, id='4'),\n",
              " HumanMessage(content='Message 5', additional_kwargs={}, response_metadata={}, id='5'),\n",
              " AIMessage(content='Message 6', additional_kwargs={}, response_metadata={}, id='6'),\n",
              " HumanMessage(content='Message 7', additional_kwargs={}, response_metadata={}, id='7')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "messages = [\n",
        "    HumanMessage(content=\"Message 1\", id=\"1\"),\n",
        "    AIMessage(content=\"Message 2\", id=\"2\"),\n",
        "    HumanMessage(content=\"Message 3\", id=\"3\"),\n",
        "    AIMessage(content=\"Message 4\", id=\"4\"),\n",
        "    HumanMessage(content=\"Message 5\", id=\"5\"),\n",
        "    AIMessage(content=\"Message 6\", id=\"6\")\n",
        "]\n",
        "\n",
        "new_message = HumanMessage(content=\"Message 7\", id=\"7\")\n",
        "\n",
        "# Test\n",
        "messages = add_messages(messages , new_message)\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3J2zwIO4_v2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12960ba9-c561-4e9d-ceec-b301023672ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='1'),\n",
              " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='2'),\n",
              " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='3'),\n",
              " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='4'),\n",
              " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='5')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langchain_core.messages import RemoveMessage\n",
        "\n",
        "# Isolate messages to delete\n",
        "delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]\n",
        "delete_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1vpV6gWB_v2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c481896d-449b-42a5-cc16-0bfc6c6ac4ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Message 6', additional_kwargs={}, response_metadata={}, id='6'),\n",
              " HumanMessage(content='Message 7', additional_kwargs={}, response_metadata={}, id='7')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "messages = add_messages(messages , delete_messages)\n",
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvTELqBj_v2s"
      },
      "source": [
        "## Summarization chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RChF8whS_v2s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "30ca5a3f-6a3a-41b0-d033-79312544cf24"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Defining Schema\n",
        "##################################################################################\n",
        "class SummaryState(State):\n",
        "    summary: str\n",
        "\n",
        "# Nodes\n",
        "def chatbot(state: SummaryState) -> SummaryState:\n",
        "    summary = state.get(\"summary\", \"\") # getting summary if it exists\n",
        "\n",
        "    # If there is summary, then we add it\n",
        "    if summary:\n",
        "        # define summary as SystemMessage\n",
        "        summary_message = SystemMessage(content=(f\"\"\"\n",
        "        Summary of Conversation:\n",
        "\n",
        "        {summary}\n",
        "        \"\"\"))\n",
        "\n",
        "        messages_with_summary = [summary_message] + state[\"messages\"]\n",
        "\n",
        "    else:\n",
        "        messages_with_summary = state[\"messages\"]\n",
        "\n",
        "\n",
        "    question = HumanMessage(content=state.get(\"question\", \"\"))\n",
        "\n",
        "    response = llm.invoke([chatbot_system_message] + messages_with_summary + [question]);\n",
        "\n",
        "    return SummaryState(\n",
        "        messages = [question, response],\n",
        "        question = state.get(\"question\", None),\n",
        "        answer = response.content,\n",
        "        summary = state.get(\"summary\", None)\n",
        "    )\n",
        "\n",
        "\n",
        "def summarize(state: SummaryState) -> SummaryState:\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "    # no system message\n",
        "    # the order of components is important\n",
        "\n",
        "    if summary:\n",
        "        summary_message = HumanMessage(content=(f\"\"\"\n",
        "            Expand the summary below by incorporating the above conversation while preserving context, key points, and\n",
        "            user intent. Rework the summary if needed. Ensure that no critical information is lost and that the\n",
        "            conversation can continue naturally without gaps. Keep the summary concise yet informative, removing\n",
        "            unnecessary repetition while maintaining clarity.\n",
        "\n",
        "            Only return the updated summary. Do not add explanations, section headers, or extra commentary.\n",
        "\n",
        "            Existing summary:\n",
        "\n",
        "            {summary}\n",
        "            \"\"\")\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        summary_message = HumanMessage(content=\"\"\"\n",
        "        Summarize the above conversation while preserving full context, key points, and user intent. Your response\n",
        "        should be concise yet detailed enough to ensure seamless continuation of the discussion. Avoid redundancy,\n",
        "        maintain clarity, and retain all necessary details for future exchanges.\n",
        "\n",
        "        Only return the summarized content. Do not add explanations, section headers, or extra commentary.\n",
        "        \"\"\")\n",
        "\n",
        "    # Add prompt to our history\n",
        "    messages = state[\"messages\"] + [summary_message]\n",
        "    response = llm.invoke(messages)\n",
        "\n",
        "    # Delete all but the 2 most recent messages\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "\n",
        "    return SummaryState(\n",
        "        messages = delete_messages,\n",
        "        question = state.get(\"question\", None),\n",
        "        answer = state.get(\"answer\", None),\n",
        "        summary = response.content\n",
        "    )\n",
        "\n",
        "\n",
        "# Edges\n",
        "\n",
        "# Determine whether to end or summarize the conversation\n",
        "def should_summarize(state: SummaryState):\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    if len(messages) > 2:\n",
        "        return \"summarize\"\n",
        "\n",
        "    return END\n",
        "\n",
        "\n",
        "# Graph\n",
        "workflow = StateGraph(SummaryState)\n",
        "workflow.add_node(chatbot)\n",
        "workflow.add_node(summarize)\n",
        "\n",
        "workflow.add_edge(START, \"chatbot\")\n",
        "workflow.add_conditional_edges(\"chatbot\", should_summarize)\n",
        "workflow.add_edge(\"summarize\", END)\n",
        "\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "joVG2CY4_v2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5d2474-0089-4b23-f3d4-36a4b671d88c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='0c7a8c01-2977-4cf0-a5e1-4b53051c3cd6'),\n",
              "  AIMessage(content='I’d be happy to help! What specific issues are you facing with API responses in your Python project? Are you having trouble with making requests, parsing the responses, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 89, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4pJ6aNFT88hiJ4hLgFcPlbS2kFs7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--554c6450-d333-4a5f-8efb-9e2c616dd391-0', usage_metadata={'input_tokens': 89, 'output_tokens': 37, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
              " 'answer': 'I’d be happy to help! What specific issues are you facing with API responses in your Python project? Are you having trouble with making requests, parsing the responses, or something else?',\n",
              " 'summary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "thread_id = \"1\"\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "graph.invoke(State(question=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XYguYVrJ_v2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66556186-9286-4362-bbbd-e6299da87050"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Sorry what was my previous question?', additional_kwargs={}, response_metadata={}, id='62e5c8e6-0819-448a-8641-a66002a1dd15'),\n",
              "  AIMessage(content='You mentioned that you were working on a Python project and were stuck with handling API responses. How can I assist you further with that?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 141, 'total_tokens': 168, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4pJGXOtz4JXBeTXrmwJlcQFJlTgH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0b29a789-1e19-4771-b413-6aaa10b6f786-0', usage_metadata={'input_tokens': 141, 'output_tokens': 27, 'total_tokens': 168, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Sorry what was my previous question?',\n",
              " 'answer': 'You mentioned that you were working on a Python project and were stuck with handling API responses. How can I assist you further with that?',\n",
              " 'summary': 'The user is working on a Python project and is facing difficulties with handling API responses. They reached out for help regarding specific issues related to making requests or parsing the responses. The assistant sought clarification to provide further assistance.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "graph.invoke(State(question=\"Sorry what was my previous question?\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kVx810q__v2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ff6fb7-5289-45d8-828e-b8b23f3a043a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.', additional_kwargs={}, response_metadata={}, id='6faba062-2dc2-4883-a3d7-cdd9a0d00249'),\n",
              "  AIMessage(content='I understand. Parsing JSON can be tricky, especially if the structure varies. Here are a few tips to handle unexpected JSON structures:\\n\\n1. **Use `try-except` Blocks**: Wrap your parsing code in `try-except` blocks to handle exceptions gracefully when the structure isn\\'t as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       print(data[\\'expected_key\\'])\\n   except KeyError:\\n       print(\"Expected key not found in the response.\")\\n   except json.JSONDecodeError:\\n       print(\"Failed to decode JSON.\")\\n   ```\\n\\n2. **Check Structure Before Accessing**: Before accessing nested keys, check if they exist.\\n\\n   ```python\\n   if \\'key1\\' in data and \\'key2\\' in data[\\'key1\\']:\\n       value = data[\\'key1\\'][\\'key2\\']\\n   ```\\n\\n3. **Use the `get()` Method**: This method allows you to specify a default value if the key doesn’t exist.\\n\\n   ```python\\n   value = data.get(\\'key1\\', {}).get(\\'key2\\', \\'default_value\\')\\n   ```\\n\\n4. **Print the Entire Response**: If you\\'re unsure about the structure, print the entire JSON response to understand it better.\\n\\n   ```python\\n   print(json.dumps(data, indent=4))\\n   ```\\n\\nFeel free to provide a sample JSON response if you need more specific help!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 302, 'prompt_tokens': 198, 'total_tokens': 500, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1542007cca', 'id': 'chatcmpl-C4pJSByv3SQYae0Xo28R6vnj6fWwM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bbcbb380-55ff-4669-a7b0-1a7a6ec2e9b1-0', usage_metadata={'input_tokens': 198, 'output_tokens': 302, 'total_tokens': 500, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
              " 'answer': 'I understand. Parsing JSON can be tricky, especially if the structure varies. Here are a few tips to handle unexpected JSON structures:\\n\\n1. **Use `try-except` Blocks**: Wrap your parsing code in `try-except` blocks to handle exceptions gracefully when the structure isn\\'t as expected.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"key\": \"value\"}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       print(data[\\'expected_key\\'])\\n   except KeyError:\\n       print(\"Expected key not found in the response.\")\\n   except json.JSONDecodeError:\\n       print(\"Failed to decode JSON.\")\\n   ```\\n\\n2. **Check Structure Before Accessing**: Before accessing nested keys, check if they exist.\\n\\n   ```python\\n   if \\'key1\\' in data and \\'key2\\' in data[\\'key1\\']:\\n       value = data[\\'key1\\'][\\'key2\\']\\n   ```\\n\\n3. **Use the `get()` Method**: This method allows you to specify a default value if the key doesn’t exist.\\n\\n   ```python\\n   value = data.get(\\'key1\\', {}).get(\\'key2\\', \\'default_value\\')\\n   ```\\n\\n4. **Print the Entire Response**: If you\\'re unsure about the structure, print the entire JSON response to understand it better.\\n\\n   ```python\\n   print(json.dumps(data, indent=4))\\n   ```\\n\\nFeel free to provide a sample JSON response if you need more specific help!',\n",
              " 'summary': 'The user is working on a Python project and is struggling with parsing JSON responses from API calls. They encounter issues when the JSON structure varies from their expectations, which breaks their code. The assistant provided several tips for robust JSON handling, including using `try-except` blocks to catch exceptions, checking for key existence before accessing values, utilizing the `get()` method for safe access, and advising to print the entire response to understand its structure better. The user is encouraged to share a sample JSON response for more specific assistance.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "graph.invoke(State(question=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aMoE_Xbl_v2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19744490-b6db-47a7-e275-24526977ef66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?', additional_kwargs={}, response_metadata={}, id='47fc65ec-9911-4632-b0aa-1d7a205dc2c7'),\n",
              "  AIMessage(content=\"When dealing with deeply nested JSON data, and you only need a few specific values, it's best to navigate through the structure carefully to avoid breaking your code. Here are some strategies to effectively handle such cases:\\n\\n1. **Use a Recursive Function**: If the nesting is unpredictable, you can create a recursive function to traverse the JSON tree and extract the values you're interested in.\\n\\n   ```python\\n   def find_values(data, keys):\\n       if isinstance(data, dict):\\n           for key in keys:\\n               if key in data:\\n                   yield data[key]\\n           for value in data.values():\\n               yield from find_values(value, keys)\\n       elif isinstance(data, list):\\n           for item in data:\\n               yield from find_values(item, keys)\\n\\n   # Example usage:\\n   response = json.loads(your_json_string)\\n   results = list(find_values(response, ['target_key1', 'target_key2']))\\n   print(results)\\n   ```\\n\\n2. **Use Optional Chaining with `get()`**: For more predictable structures, use `get()` multiple times to access nested values without raising `KeyError`.\\n\\n   ```python\\n   value1 = data.get('key1', {}).get('key2', {}).get('target_key', 'default_value')\\n   ```\\n\\n3. **Data Extraction Library**: Consider using libraries like `jsonpath-ng` or `jmespath` for more complex queries on JSON data. These libraries allow you to specify paths to retrieve values easily.\\n\\n   ```python\\n   from jmespath import search\\n\\n   # Assuming 'data' contains your JSON response\\n   result = search('key1.key2.target_key', data)\\n   print(result)\\n   ```\\n\\n4. **Localize Access**: If you know the exact path you need, assign intermediate objects to variables to avoid long chains of `get()`.\\n\\n   ```python\\n   key1_data = data.get('key1', {})\\n   key2_data = key1_data.get('key2', {})\\n   target_value = key2_data.get('target_key', 'default_value')\\n   ```\\n\\nUsing these methods, you can safely and effectively extract the values you need from deeply nested JSON data. If you have specific values in mind or a sample JSON structure, I can help you tailor the approach further!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 465, 'prompt_tokens': 556, 'total_tokens': 1021, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4pJjJLc7hCYGLGMnchYhWGYThrD2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--30c4d5a8-50ec-43a6-89be-1b49ef99a5be-0', usage_metadata={'input_tokens': 556, 'output_tokens': 465, 'total_tokens': 1021, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?',\n",
              " 'answer': \"When dealing with deeply nested JSON data, and you only need a few specific values, it's best to navigate through the structure carefully to avoid breaking your code. Here are some strategies to effectively handle such cases:\\n\\n1. **Use a Recursive Function**: If the nesting is unpredictable, you can create a recursive function to traverse the JSON tree and extract the values you're interested in.\\n\\n   ```python\\n   def find_values(data, keys):\\n       if isinstance(data, dict):\\n           for key in keys:\\n               if key in data:\\n                   yield data[key]\\n           for value in data.values():\\n               yield from find_values(value, keys)\\n       elif isinstance(data, list):\\n           for item in data:\\n               yield from find_values(item, keys)\\n\\n   # Example usage:\\n   response = json.loads(your_json_string)\\n   results = list(find_values(response, ['target_key1', 'target_key2']))\\n   print(results)\\n   ```\\n\\n2. **Use Optional Chaining with `get()`**: For more predictable structures, use `get()` multiple times to access nested values without raising `KeyError`.\\n\\n   ```python\\n   value1 = data.get('key1', {}).get('key2', {}).get('target_key', 'default_value')\\n   ```\\n\\n3. **Data Extraction Library**: Consider using libraries like `jsonpath-ng` or `jmespath` for more complex queries on JSON data. These libraries allow you to specify paths to retrieve values easily.\\n\\n   ```python\\n   from jmespath import search\\n\\n   # Assuming 'data' contains your JSON response\\n   result = search('key1.key2.target_key', data)\\n   print(result)\\n   ```\\n\\n4. **Localize Access**: If you know the exact path you need, assign intermediate objects to variables to avoid long chains of `get()`.\\n\\n   ```python\\n   key1_data = data.get('key1', {})\\n   key2_data = key1_data.get('key2', {})\\n   target_value = key2_data.get('target_key', 'default_value')\\n   ```\\n\\nUsing these methods, you can safely and effectively extract the values you need from deeply nested JSON data. If you have specific values in mind or a sample JSON structure, I can help you tailor the approach further!\",\n",
              " 'summary': 'The user is working on a Python project and is facing challenges with parsing JSON responses from API calls, particularly when the JSON structure varies unexpectedly. This leads to code failures. The assistant offered several strategies for handling JSON robustly, such as using `try-except` blocks for error handling, checking for key existence before accessing values, and utilizing the `get()` method for safe access. The assistant also recommended printing the entire JSON response for better understanding and suggested more advanced techniques for dealing with deeply nested JSON, including creating a recursive function, using optional chaining, and leveraging data extraction libraries like `jsonpath-ng` or `jmespath`. The user is encouraged to share a specific JSON response or specific values they need help with for further assistance.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "graph.invoke(State(question=\"Got it! That helps a lot. What would be the best way to handle deeply nested JSON data when I only need a few specific values?\"), config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o_oVAtrI_v2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510a072f-b870-42c0-ae31-344354021721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='How is the weather outside?', additional_kwargs={}, response_metadata={}, id='90b18464-fb93-465d-b44d-930fc4a6221f'),\n",
              "  AIMessage(content=\"I'm unable to provide real-time information, such as current weather conditions. However, you can check the weather using a weather website, app, or by calling an API service like OpenWeatherMap or WeatherAPI to get up-to-date information. If you need help with how to fetch weather data using Python or an API, let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 739, 'total_tokens': 807, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4pKAe1lhgHEWiqhPHYER35JCgIpc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--df2db9d8-13df-4250-9184-7dc784f1a9b5-0', usage_metadata={'input_tokens': 739, 'output_tokens': 68, 'total_tokens': 807, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'question': 'How is the weather outside?',\n",
              " 'answer': \"I'm unable to provide real-time information, such as current weather conditions. However, you can check the weather using a weather website, app, or by calling an API service like OpenWeatherMap or WeatherAPI to get up-to-date information. If you need help with how to fetch weather data using Python or an API, let me know!\",\n",
              " 'summary': 'The user is working on a Python project and encountering challenges when parsing JSON responses from API calls, especially when the JSON structure is deeply nested and varies unexpectedly, leading to code failures. The assistant provided several strategies for robust JSON handling, including using `try-except` blocks for error management, checking for key existence, and employing the `get()` method for safe value access. Additionally, the assistant suggested printing the entire JSON response for better understanding and recommended advanced techniques for handling deeply nested JSON, such as creating a recursive function, using optional chaining with `get()`, and leveraging data extraction libraries like `jsonpath-ng` or `jmespath`. The user also inquired about the weather, to which the assistant advised checking real-time information via weather websites or APIs, offering further assistance with fetching weather data in Python if needed. The user is encouraged to share specific JSON responses or values for more targeted help.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "graph.invoke(State(question=\"How is the weather outside?\"), config)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}