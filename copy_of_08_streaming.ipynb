{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangGraph API\n",
    "\n",
    "Tell about server part of LangGraph Studio and prefered approach to build graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '45d7f46b-abb2-5734-9fb9-b1edc76c6546',\n",
       "  'graph_id': 'dev_mentor',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'dev_mentor',\n",
       "  'created_at': '2025-08-15T17:20:59.259433+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.259433+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': 'ae2c32e4-0e45-57db-b449-103064dcb967',\n",
       "  'graph_id': 'directive_memory_bot',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'directive_memory_bot',\n",
       "  'created_at': '2025-08-15T17:20:59.156435+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.156435+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '89e77aa6-c452-5416-bd83-721b80077ae5',\n",
       "  'graph_id': 'chatbot_long_term_memory',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'chatbot_long_term_memory',\n",
       "  'created_at': '2025-08-15T17:20:59.046553+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.046553+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '01914b9c-2e77-57a1-bbc3-9f3db62c1c8d',\n",
       "  'graph_id': 'map_reduce',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'map_reduce',\n",
       "  'created_at': '2025-08-15T17:20:59.037931+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.037931+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '7888c1c8-1376-532f-98c7-254f4e50307f',\n",
       "  'graph_id': 'financial_advisor_intent_check',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'financial_advisor_intent_check',\n",
       "  'created_at': '2025-08-15T17:20:59.029747+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.029747+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '09819134-dfce-5fe3-b464-bbd3881a89df',\n",
       "  'graph_id': 'financial_advisor_breakpoint',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'financial_advisor_breakpoint',\n",
       "  'created_at': '2025-08-15T17:20:58.959417+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:58.959417+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': 'b7480eb0-6390-53a5-9bc4-29bf27cbd1c4',\n",
       "  'graph_id': 'financial_advisor',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'financial_advisor',\n",
       "  'created_at': '2025-08-15T17:20:58.882281+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:58.882281+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7',\n",
       "  'graph_id': 'chatbot',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'chatbot',\n",
       "  'created_at': '2025-08-15T17:20:54.987788+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:54.987788+00:00',\n",
       "  'version': 1,\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# URL = \"http://localhost:61693\"\n",
    "URL = \"http://127.0.0.1:2024\"  # This is the server address\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()\n",
    "assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'45d7f46b-abb2-5734-9fb9-b1edc76c6546'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants[0][\"assistant_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
       "   'additional_kwargs': {},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': '202bdeb0-5874-4a94-83a9-59ff924b0d72',\n",
       "   'example': False},\n",
       "  {'content': \"I'd be happy to help! Could you provide more details about the API you are working with and what specific issues or questions you have regarding handling the responses?\",\n",
       "   'additional_kwargs': {'refusal': None},\n",
       "   'response_metadata': {'token_usage': {'completion_tokens': 31,\n",
       "     'prompt_tokens': 92,\n",
       "     'total_tokens': 123,\n",
       "     'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "      'audio_tokens': 0,\n",
       "      'reasoning_tokens': 0,\n",
       "      'rejected_prediction_tokens': 0},\n",
       "     'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "    'system_fingerprint': 'fp_1542007cca',\n",
       "    'id': 'chatcmpl-C4spusGVUGCQFTPU6ENdX83gEHwP6',\n",
       "    'service_tier': 'default',\n",
       "    'finish_reason': 'stop',\n",
       "    'logprobs': None},\n",
       "   'type': 'ai',\n",
       "   'name': None,\n",
       "   'id': 'run--dbefa30f-b461-4299-a401-fbfa47b6d030-0',\n",
       "   'example': False,\n",
       "   'tool_calls': [],\n",
       "   'invalid_tool_calls': [],\n",
       "   'usage_metadata': {'input_tokens': 92,\n",
       "    'output_tokens': 31,\n",
       "    'total_tokens': 123,\n",
       "    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "    'output_token_details': {'audio': 0, 'reasoning': 0}}}],\n",
       " 'question': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
       " 'answer': \"I'd be happy to help! Could you provide more details about the API you are working with and what specific issues or questions you have regarding handling the responses?\",\n",
       " 'summary': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "final_state = await client.runs.wait(\n",
    "    thread_id=thread[\"thread_id\"],\n",
    "    assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\",\n",
    "    input={\"question\": \"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\"}\n",
    ")\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You mentioned that you are working on a Python project and are having trouble handling API responses. If you could provide more details about the specific issues you're encountering, I can assist you better!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = await client.runs.wait(\n",
    "    thread_id=thread[\"thread_id\"],\n",
    "    assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\",\n",
    "    input={\"question\": \"Sorry what was my previous question?\"}\n",
    ")\n",
    "\n",
    "final_state[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
       "   'additional_kwargs': {},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': 'c7590e25-f838-4293-acb4-3acc1b724174',\n",
       "   'example': False},\n",
       "  {'content': 'I understand! When dealing with JSON responses, unexpected structures can definitely be a challenge. Here are some tips to help you handle them more effectively:\\n\\n1. **Check the Structure**: Always print or log the entire JSON response first to understand its structure. You can use `print(response.json())` after parsing it with `response.json()`.\\n\\n2. **Use `try-except` Blocks**: To handle potential parsing errors, wrap your JSON parsing logic in a `try-except` block. This will allow you to catch and manage exceptions gracefully.\\n\\n   ```python\\n   import requests\\n\\n   response = requests.get(\\'your_api_endpoint\\')\\n   try:\\n       data = response.json()\\n       # Access data as needed\\n   except ValueError as e:\\n       print(\"Failed to parse JSON:\", e)\\n   ```\\n\\n3. **Check for Keys Before Accessing**: Use the `.get()` method or check if keys exist to avoid `KeyError`.\\n\\n   ```python\\n   value = data.get(\\'key\\', \\'default_value\\')  # Avoids KeyError by providing a default\\n   ```\\n\\n4. **Handle Optional Fields**: If certain fields may not always be present, account for that in your code.\\n\\n5. **Use a Validation Library**: Consider using libraries like `jsonschema` to validate your JSON structure against a predefined schema.\\n\\nIf you provide a specific example of a JSON response you\\'re working with, I can help you write code to parse it correctly!',\n",
       "   'additional_kwargs': {'refusal': None},\n",
       "   'response_metadata': {'token_usage': {'completion_tokens': 300,\n",
       "     'prompt_tokens': 207,\n",
       "     'total_tokens': 507,\n",
       "     'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "      'audio_tokens': 0,\n",
       "      'reasoning_tokens': 0,\n",
       "      'rejected_prediction_tokens': 0},\n",
       "     'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "    'system_fingerprint': 'fp_560af6e559',\n",
       "    'id': 'chatcmpl-C4t81V0gbtu7BVjfNuPKVs0M1PtHW',\n",
       "    'service_tier': 'default',\n",
       "    'finish_reason': 'stop',\n",
       "    'logprobs': None},\n",
       "   'type': 'ai',\n",
       "   'name': None,\n",
       "   'id': 'run--9399c8fc-6b1d-4290-bfb5-d44802d8f19d-0',\n",
       "   'example': False,\n",
       "   'tool_calls': [],\n",
       "   'invalid_tool_calls': [],\n",
       "   'usage_metadata': {'input_tokens': 207,\n",
       "    'output_tokens': 300,\n",
       "    'total_tokens': 507,\n",
       "    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "    'output_token_details': {'audio': 0, 'reasoning': 0}}}],\n",
       " 'question': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
       " 'answer': 'I understand! When dealing with JSON responses, unexpected structures can definitely be a challenge. Here are some tips to help you handle them more effectively:\\n\\n1. **Check the Structure**: Always print or log the entire JSON response first to understand its structure. You can use `print(response.json())` after parsing it with `response.json()`.\\n\\n2. **Use `try-except` Blocks**: To handle potential parsing errors, wrap your JSON parsing logic in a `try-except` block. This will allow you to catch and manage exceptions gracefully.\\n\\n   ```python\\n   import requests\\n\\n   response = requests.get(\\'your_api_endpoint\\')\\n   try:\\n       data = response.json()\\n       # Access data as needed\\n   except ValueError as e:\\n       print(\"Failed to parse JSON:\", e)\\n   ```\\n\\n3. **Check for Keys Before Accessing**: Use the `.get()` method or check if keys exist to avoid `KeyError`.\\n\\n   ```python\\n   value = data.get(\\'key\\', \\'default_value\\')  # Avoids KeyError by providing a default\\n   ```\\n\\n4. **Handle Optional Fields**: If certain fields may not always be present, account for that in your code.\\n\\n5. **Use a Validation Library**: Consider using libraries like `jsonschema` to validate your JSON structure against a predefined schema.\\n\\nIf you provide a specific example of a JSON response you\\'re working with, I can help you write code to parse it correctly!',\n",
       " 'summary': 'The user is working on a Python project and is facing challenges with parsing JSON responses from API calls, especially when the structure is not as expected. They express a desire for assistance in resolving these issues and are encouraged to provide specific examples to facilitate better support. Suggestions have been offered, including printing the JSON structure for clarity, using try-except blocks for error handling, checking for keys before accessing them, and considering validation libraries for more complex structures.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = await client.runs.wait(\n",
    "    thread_id=thread[\"thread_id\"],\n",
    "    assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\",\n",
    "    input={\"question\": \"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\"}\n",
    ")\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Observe the difference between constructing graph manually & using LangGraph Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define chatbot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, RemoveMessage\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY environment variable must be set\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# System message\n",
    "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
    "You are a helpful and knowledgeable chatbot assistant. \n",
    "Your goal is to provide clear and accurate answers to user questions based on the information they provide. \n",
    "Stay focused, concise, and ensure your responses are relevant to the context of the conversation. \n",
    "If you don’t have enough information, ask for clarification.”\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def chatbot(state: MessagesState) -> MessagesState:\n",
    "    response = llm.invoke([chatbot_system_message] + state[\"messages\"]);\n",
    "    return MessagesState(messages = [response])\n",
    "\n",
    "\n",
    "# Graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(chatbot)\n",
    "\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "workflow.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming modes:\n",
    "\n",
    "- updates (exposes only new data)\n",
    "- values (always shows the whole state)\n",
    "- messages\n",
    "- debug\n",
    "- custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream_mode=updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='Sure! To help you effectively, could you provide more details about the following?\\n\\n1. Which API are you working with?\\n2. What kind of data are you expecting in the response?\\n3. What specific issues are you facing (e.g., parsing JSON, error handling, etc.)? \\n\\nThis information will help me assist you better!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 147, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4tB23e0kufqJcsTz433ZIbNlWnJV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--663620e2-afcd-4049-a04a-5c572c6dfdf4-0', usage_metadata={'input_tokens': 147, 'output_tokens': 69, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"updates\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your previous message mentioned that you are working on a Python project and are stuck with handling API responses. If you have any specific questions or issues regarding this, feel free to share!\n"
     ]
    }
   ],
   "source": [
    "user_input = HumanMessage(content=\"Sorry what was my previous question?\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"updates\"):\n",
    "    for m in event['chatbot']['messages']:\n",
    "        m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream_mode=values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='69d8c0a4-f168-4529-90cf-c560da6e5c6a')]}\n",
      "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='69d8c0a4-f168-4529-90cf-c560da6e5c6a'), AIMessage(content=\"Sure! Could you provide more details about the specific issue you're facing with handling API responses in your Python project? For example, are you having trouble with parsing JSON data, handling errors, or anything else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 92, 'total_tokens': 133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4tCLwRHbNGOSWPHOe2QafAX5Exzx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ea34ad4e-ba84-4c9c-bde1-8ed0288cd25b-0', usage_metadata={'input_tokens': 92, 'output_tokens': 41, 'total_tokens': 133, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Could you provide more details about the specific issue you're facing with handling API responses in your Python project? For example, are you having trouble with parsing JSON data, handling errors, or anything else?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Could you provide more details about the specific issue you're facing with handling API responses in your Python project? For example, are you having trouble with parsing JSON data, handling errors, or anything else?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with that! Could you specify what aspect of handling API responses you're struggling with? For example, are you having trouble parsing the response, dealing with different response formats, handling errors, or making the API request itself? Any specific code snippets or error messages would also be helpful!\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming deeper (updates inside Node) - a.k.a. \"streaming LLM tokens from a specific node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='I', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='’d', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' happy', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' help', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' What', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' issues', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' facing', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' handling', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' API', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' responses', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' your', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' Python', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' project', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' Are', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' having', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' trouble', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' making', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' requests', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' parsing', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' responses', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' something', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' else', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, id='run--bc2c83b5-994a-40b2-928f-49999aa04e18'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ('branch:to:chatbot',), 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'checkpoint_ns': 'chatbot:9b6b63c0-aade-1c97-15ce-136b53f69ebe', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"messages\"):\n",
    "    print(event)\n",
    "\n",
    "# so we have a message with content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing JSON responses can sometimes be tricky due to variable structures. Here are a few tips to handle potential issues:\n",
      "\n",
      "1. **Use `try-except` Blocks**: Wrap your parsing code in try-except blocks to handle potential errors gracefully.\n",
      "\n",
      "   ```python\n",
      "   import json\n",
      "\n",
      "   try:\n",
      "       response_data = json.loads(api_response)  # Replace api_response with your API response\n",
      "   except json.JSONDecodeError:\n",
      "       print(\"Failed to decode JSON\")\n",
      "   ```\n",
      "\n",
      "2. **Check the Response Structure**: Before accessing certain keys, ensure they exist to avoid `KeyError`.\n",
      "\n",
      "   ```python\n",
      "   if 'key' in response_data:\n",
      "       value = response_data['key']\n",
      "   else:\n",
      "       print(\"Key not found in response\")\n",
      "   ```\n",
      "\n",
      "3. **Use `get()` Method**: The `get()` method returns `None` if a key doesn't exist, preventing errors.\n",
      "\n",
      "   ```python\n",
      "   value = response_data.get('key', default_value)  # Use a default if the key is missing\n",
      "   ```\n",
      "\n",
      "4. **Print the Response**: When debugging, print the entire JSON response to understand its structure.\n",
      "\n",
      "   ```python\n",
      "   print(json.dumps(response_data, indent=4))  # Pretty print the JSON\n",
      "   ```\n",
      "\n",
      "5. **Explore the Structure**: If the API response structure can vary, consider using recursion or a loop to drill down through nested structures.\n",
      "\n",
      "If you provide an example of an API response you’re trying to work with, I can help you with specific code to handle it!"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\")\n",
    "for msg, metadata in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"messages\"):\n",
    "    if (metadata['langgraph_node'] == 'chatbot'):\n",
    "        print(msg.content, end=\"\")\n",
    "\n",
    "# same style of outputing data as in chat app (a token by token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming with LangGraph API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '45d7f46b-abb2-5734-9fb9-b1edc76c6546',\n",
       "  'graph_id': 'dev_mentor',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'dev_mentor',\n",
       "  'created_at': '2025-08-15T17:20:59.259433+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.259433+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': 'ae2c32e4-0e45-57db-b449-103064dcb967',\n",
       "  'graph_id': 'directive_memory_bot',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'directive_memory_bot',\n",
       "  'created_at': '2025-08-15T17:20:59.156435+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.156435+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '89e77aa6-c452-5416-bd83-721b80077ae5',\n",
       "  'graph_id': 'chatbot_long_term_memory',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'chatbot_long_term_memory',\n",
       "  'created_at': '2025-08-15T17:20:59.046553+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.046553+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '01914b9c-2e77-57a1-bbc3-9f3db62c1c8d',\n",
       "  'graph_id': 'map_reduce',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'map_reduce',\n",
       "  'created_at': '2025-08-15T17:20:59.037931+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.037931+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '7888c1c8-1376-532f-98c7-254f4e50307f',\n",
       "  'graph_id': 'financial_advisor_intent_check',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'financial_advisor_intent_check',\n",
       "  'created_at': '2025-08-15T17:20:59.029747+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:59.029747+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '09819134-dfce-5fe3-b464-bbd3881a89df',\n",
       "  'graph_id': 'financial_advisor_breakpoint',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'financial_advisor_breakpoint',\n",
       "  'created_at': '2025-08-15T17:20:58.959417+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:58.959417+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': 'b7480eb0-6390-53a5-9bc4-29bf27cbd1c4',\n",
       "  'graph_id': 'financial_advisor',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'financial_advisor',\n",
       "  'created_at': '2025-08-15T17:20:58.882281+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:58.882281+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7',\n",
       "  'graph_id': 'chatbot',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'chatbot',\n",
       "  'created_at': '2025-08-15T17:20:54.987788+00:00',\n",
       "  'updated_at': '2025-08-15T17:20:54.987788+00:00',\n",
       "  'version': 1,\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "#URL = \"http://localhost:61693\"\n",
    "URL = \"http://127.0.0.1:2024\"  # This is the server address\n",
    "client = get_client(url=URL)\n",
    "\n",
    "assistants = await client.assistants.search()\n",
    "assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f07a043-e910-62ea-bdce-04e7b60e25c4', 'attempt': 1})\n",
      "StreamPart(event='messages/metadata', data={'run--806e674a-a9d9-487b-8b95-447d0ce8eb02': {'metadata': {'created_by': 'system', 'graph_id': 'chatbot', 'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7', 'run_attempt': 1, 'langgraph_version': '0.6.4', 'langgraph_api_version': '0.2.128', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'host': '127.0.0.1:2024', 'accept-encoding': 'gzip, deflate, zstd', 'connection': 'keep-alive', 'user-agent': 'langgraph-sdk-py/0.2.0', 'x-api-key': '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', 'content-length': '350', 'content-type': 'application/json', 'accept': 'text/event-stream', 'cache-control': 'no-store', 'x-request-id': 'b5ac56b6-b8e2-4cb7-a1df-96ba3bc952a7', 'langgraph_auth_user_id': '', 'langgraph_request_id': 'b5ac56b6-b8e2-4cb7-a1df-96ba3bc952a7', 'run_id': '1f07a043-e910-62ea-bdce-04e7b60e25c4', 'thread_id': '485f9233-b790-4597-96dd-165324bee4cc', 'user_id': '', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['branch:to:chatbot'], 'langgraph_path': ['__pregel_pull', 'chatbot'], 'langgraph_checkpoint_ns': 'chatbot:acd689c8-2f20-7d45-8cf2-945aa8ff0555', 'checkpoint_ns': 'chatbot:acd689c8-2f20-7d45-8cf2-945aa8ff0555', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}}})\n",
      "StreamPart(event='messages/partial', data=[{'content': '', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure,', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide more', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide more details', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide more details about', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide more details about the', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide more details about the specific', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'Sure, I can help with that! Could you provide more details about the specific issue', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project?\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example,\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response,\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors,\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors, or\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors, or something\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors, or something else\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors, or something else?\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': \"Sure, I can help with that! Could you provide more details about the specific issue you're facing with API responses in your Python project? For example, are you having trouble parsing the response, handling errors, or something else?\", 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, 'type': 'ai', 'name': None, 'id': 'run--806e674a-a9d9-487b-8b95-447d0ce8eb02', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/metadata', data={'2e637b70-1b0c-4220-96c3-b5bc6026ff5d': {'metadata': {'created_by': 'system', 'graph_id': 'chatbot', 'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7', 'run_attempt': 1, 'langgraph_version': '0.6.4', 'langgraph_api_version': '0.2.128', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'host': '127.0.0.1:2024', 'accept-encoding': 'gzip, deflate, zstd', 'connection': 'keep-alive', 'user-agent': 'langgraph-sdk-py/0.2.0', 'x-api-key': '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', 'content-length': '350', 'content-type': 'application/json', 'accept': 'text/event-stream', 'cache-control': 'no-store', 'x-request-id': 'b5ac56b6-b8e2-4cb7-a1df-96ba3bc952a7', 'langgraph_auth_user_id': '', 'langgraph_request_id': 'b5ac56b6-b8e2-4cb7-a1df-96ba3bc952a7', 'run_id': '1f07a043-e910-62ea-bdce-04e7b60e25c4', 'thread_id': '485f9233-b790-4597-96dd-165324bee4cc', 'user_id': '', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['branch:to:chatbot'], 'langgraph_path': ['__pregel_pull', 'chatbot'], 'langgraph_checkpoint_ns': 'chatbot:acd689c8-2f20-7d45-8cf2-945aa8ff0555', 'LANGSMITH_LANGGRAPH_API_VARIANT': 'local_dev'}}})\n",
      "StreamPart(event='messages/complete', data=[{'content': '', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2e637b70-1b0c-4220-96c3-b5bc6026ff5d', 'example': False}])\n",
      "StreamPart(event='messages/metadata', data={'run--6135a50a-bb30-4bfc-b121-c2226859fcaa': {'metadata': {'created_by': 'system', 'graph_id': 'chatbot', 'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7', 'run_attempt': 1, 'langgraph_version': '0.6.4', 'langgraph_api_version': '0.2.128', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'host': '127.0.0.1:2024', 'accept-encoding': 'gzip, deflate, zstd', 'connection': 'keep-alive', 'user-agent': 'langgraph-sdk-py/0.2.0', 'x-api-key': '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', 'content-length': '350', 'content-type': 'application/json', 'accept': 'text/event-stream', 'cache-control': 'no-store', 'x-request-id': 'b5ac56b6-b8e2-4cb7-a1df-96ba3bc952a7', 'langgraph_auth_user_id': '', 'langgraph_request_id': 'b5ac56b6-b8e2-4cb7-a1df-96ba3bc952a7', 'run_id': '1f07a043-e910-62ea-bdce-04e7b60e25c4', 'thread_id': '485f9233-b790-4597-96dd-165324bee4cc', 'user_id': '', 'langgraph_step': 2, 'langgraph_node': 'summarize', 'langgraph_triggers': ['branch:to:summarize'], 'langgraph_path': ['__pregel_pull', 'summarize'], 'langgraph_checkpoint_ns': 'summarize:9d616ed0-5a26-14d9-e99f-a7aaa97507e6', 'checkpoint_ns': 'summarize:9d616ed0-5a26-14d9-e99f-a7aaa97507e6', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}}})\n",
      "StreamPart(event='messages/partial', data=[{'content': '', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing,', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling,', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of managing', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of managing the', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of managing the API', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of managing the API responses', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of managing the API responses.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n",
      "StreamPart(event='messages/partial', data=[{'content': 'The user is working on a Python project and is encountering difficulties with handling API responses. They seek assistance to resolve the specific issues related to parsing, error handling, or other aspects of managing the API responses.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, 'type': 'ai', 'name': None, 'id': 'run--6135a50a-bb30-4bfc-b121-c2226859fcaa', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}])\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "\n",
    "input_message = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "\n",
    "async for part in client.runs.stream(\n",
    "        thread[\"thread_id\"], \n",
    "        assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\", \n",
    "        input={\"messages\": [input_message]}, \n",
    "        stream_mode=\"messages\"):\n",
    "    print(part)\n",
    "\n",
    "# check event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Should I invest in Tesla stocks?' additional_kwargs={} response_metadata={} id='c4651ac5-cbbe-4ae7-882c-e5a3d1b4d486'\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 392, 'output_tokens': 17, 'total_tokens': 409, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [{'id': 'call_tKMcPnaUu9CxyYNgie4GV2La', 'function': {'arguments': '{\"__arg1\":\"Tesla\"}', 'name': 'lookup_stock_symbol'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 392, 'total_tokens': 409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4tQK0Ucw9vMlTDUqKeNPzpaHoX6G', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--f23eb96e-966e-459a-baa8-d48630d4e2ff-0' tool_calls=[{'name': 'lookup_stock_symbol', 'args': {'__arg1': 'Tesla'}, 'id': 'call_tKMcPnaUu9CxyYNgie4GV2La', 'type': 'tool_call'}]\n",
      "content='TSLA' name='lookup_stock_symbol' id='a53b22ee-7ba4-4813-930e-e36b79f6e7d6' tool_call_id='call_tKMcPnaUu9CxyYNgie4GV2La'\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 420, 'output_tokens': 19, 'total_tokens': 439, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [{'id': 'call_R1MQuPOJby5zLEUx25opaWVu', 'function': {'arguments': '{\"__arg1\":\"TSLA\"}', 'name': 'fetch_stock_data_raw'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 420, 'total_tokens': 439, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C4tQM6jtUtPDWJQiiOsXRgQ2XTgcD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--d3b128d6-3e1c-4492-9182-0c760e0b25cc-0' tool_calls=[{'name': 'fetch_stock_data_raw', 'args': {'__arg1': 'TSLA'}, 'id': 'call_R1MQuPOJby5zLEUx25opaWVu', 'type': 'tool_call'}]\n",
      "content=\"{'history': {'Close': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 310.7799987792969,\\n                       Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 321.6700134277344,\\n                       Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 319.4100036621094,\\n                       Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 329.6499938964844,\\n                       Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 328.489990234375,\\n                       Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 332.1099853515625,\\n                       Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 332.55999755859375,\\n                       Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 305.29998779296875,\\n                       Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 316.05999755859375,\\n                       Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 325.5899963378906,\\n                       Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 321.20001220703125,\\n                       Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 319.0400085449219,\\n                       Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 308.2699890136719,\\n                       Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 302.6300048828125,\\n                       Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 309.260009765625,\\n                       Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 308.7200012207031,\\n                       Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 319.9100036621094,\\n                       Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 322.2699890136719,\\n                       Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 329.6499938964844,\\n                       Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 339.0299987792969,\\n                       Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 340.8399963378906,\\n                       Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 339.3800048828125,\\n                       Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 335.5799865722656,\\n                       Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 329.56500244140625},\\n             'Dividends': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 0.0,\\n                           Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 0.0},\\n             'High': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 321.20001220703125,\\n                      Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 323.5,\\n                      Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 324.3399963378906,\\n                      Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 330.8999938964844,\\n                      Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 338.0,\\n                      Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 335.4100036621094,\\n                      Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 336.20001220703125,\\n                      Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 310.1499938964844,\\n                      Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 323.6300048828125,\\n                      Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 330.489990234375,\\n                      Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 326.25,\\n                      Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 324.45001220703125,\\n                      Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 321.3699951171875,\\n                      Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 309.30999755859375,\\n                      Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 312.1199951171875,\\n                      Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 312.45001220703125,\\n                      Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 320.4700012207031,\\n                      Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 322.3999938964844,\\n                      Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 335.1499938964844,\\n                      Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 346.6400146484375,\\n                      Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 345.260009765625,\\n                      Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 348.9800109863281,\\n                      Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 340.4700012207031,\\n                      Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 339.29998779296875},\\n             'Low': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 310.5,\\n                     Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 312.6199951171875,\\n                     Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 317.05999755859375,\\n                     Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 321.4200134277344,\\n                     Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 326.8800048828125,\\n                     Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 321.54998779296875,\\n                     Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 328.6700134277344,\\n                     Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 300.4100036621094,\\n                     Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 308.010009765625,\\n                     Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 315.69000244140625,\\n                     Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 318.25,\\n                     Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 311.6199951171875,\\n                     Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 306.1000061035156,\\n                     Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 297.82000732421875,\\n                     Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 303.0,\\n                     Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 305.5,\\n                     Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 306.92999267578125,\\n                     Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 316.1600036621094,\\n                     Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 320.9800109863281,\\n                     Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 334.1499938964844,\\n                     Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 332.94000244140625,\\n                     Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 338.20001220703125,\\n                     Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 330.3999938964844,\\n                     Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 327.0199890136719},\\n             'Open': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 319.67999267578125,\\n                      Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 312.79998779296875,\\n                      Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 323.1499938964844,\\n                      Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 321.6600036621094,\\n                      Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 334.3999938964844,\\n                      Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 329.739990234375,\\n                      Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 330.8999938964844,\\n                      Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 310.0,\\n                      Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 308.739990234375,\\n                      Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 318.45001220703125,\\n                      Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 325.54998779296875,\\n                      Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 322.17999267578125,\\n                      Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 319.6099853515625,\\n                      Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 306.2099914550781,\\n                      Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 309.0799865722656,\\n                      Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 308.95001220703125,\\n                      Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 307.8900146484375,\\n                      Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 319.7900085449219,\\n                      Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 321.42999267578125,\\n                      Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 335.0,\\n                      Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 345.0,\\n                      Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 341.5,\\n                      Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 335.760009765625,\\n                      Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 337.6549987792969},\\n             'Stock Splits': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 0.0,\\n                              Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 0.0},\\n             'Volume': {Timestamp('2025-07-15 00:00:00-0400', tz='America/New_York'): 77556300,\\n                        Timestamp('2025-07-16 00:00:00-0400', tz='America/New_York'): 97284800,\\n                        Timestamp('2025-07-17 00:00:00-0400', tz='America/New_York'): 73922900,\\n                        Timestamp('2025-07-18 00:00:00-0400', tz='America/New_York'): 94255000,\\n                        Timestamp('2025-07-21 00:00:00-0400', tz='America/New_York'): 75768800,\\n                        Timestamp('2025-07-22 00:00:00-0400', tz='America/New_York'): 77370400,\\n                        Timestamp('2025-07-23 00:00:00-0400', tz='America/New_York'): 92553800,\\n                        Timestamp('2025-07-24 00:00:00-0400', tz='America/New_York'): 156966000,\\n                        Timestamp('2025-07-25 00:00:00-0400', tz='America/New_York'): 148227000,\\n                        Timestamp('2025-07-28 00:00:00-0400', tz='America/New_York'): 112673800,\\n                        Timestamp('2025-07-29 00:00:00-0400', tz='America/New_York'): 87358900,\\n                        Timestamp('2025-07-30 00:00:00-0400', tz='America/New_York'): 83931900,\\n                        Timestamp('2025-07-31 00:00:00-0400', tz='America/New_York'): 85270900,\\n                        Timestamp('2025-08-01 00:00:00-0400', tz='America/New_York'): 89121400,\\n                        Timestamp('2025-08-04 00:00:00-0400', tz='America/New_York'): 78683900,\\n                        Timestamp('2025-08-05 00:00:00-0400', tz='America/New_York'): 57961300,\\n                        Timestamp('2025-08-06 00:00:00-0400', tz='America/New_York'): 78523600,\\n                        Timestamp('2025-08-07 00:00:00-0400', tz='America/New_York'): 66658700,\\n                        Timestamp('2025-08-08 00:00:00-0400', tz='America/New_York'): 91200300,\\n                        Timestamp('2025-08-11 00:00:00-0400', tz='America/New_York'): 105320200,\\n                        Timestamp('2025-08-12 00:00:00-0400', tz='America/New_York'): 80522100,\\n                        Timestamp('2025-08-13 00:00:00-0400', tz='America/New_York'): 67838900,\\n                        Timestamp('2025-08-14 00:00:00-0400', tz='America/New_York'): 74812200,\\n                        Timestamp('2025-08-15 00:00:00-0400', tz='America/New_York'): 55028412}},\\n 'info': {'52WeekChange': 0.55274844,\\n          'SandP52WeekChange': 0.16461086,\\n          'address1': '1 Tesla Road',\\n          'ask': 329.91,\\n          'askSize': 1,\\n          'auditRisk': 4,\\n          'averageAnalystRating': '2.7 - Hold',\\n          'averageDailyVolume10Day': 79064260,\\n          'averageDailyVolume3Month': 103234366,\\n          'averageVolume': 103234366,\\n          'averageVolume10days': 79064260,\\n          'beta': 2.331,\\n          'bid': 328.96,\\n          'bidSize': 2,\\n          'boardRisk': 9,\\n          'bookValue': 23.981,\\n          'city': 'Austin',\\n          'companyOfficers': [{'age': 53,\\n                               'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Elon R. Musk',\\n                               'title': 'Co-Founder, Technoking of Tesla, CEO '\\n                                        '& Director',\\n                               'unexercisedValue': 0,\\n                               'yearBorn': 1971},\\n                              {'age': 46,\\n                               'exercisedValue': 9653338,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Vaibhav  Taneja',\\n                               'title': 'Chief Financial Officer',\\n                               'totalPay': 306846,\\n                               'unexercisedValue': 347210016,\\n                               'yearBorn': 1978},\\n                              {'age': 44,\\n                               'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Xiaotong  Zhu',\\n                               'title': 'Senior Vice President of APAC',\\n                               'totalPay': 518250,\\n                               'unexercisedValue': 697024064,\\n                               'yearBorn': 1980},\\n                              {'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Travis  Axelrod',\\n                               'title': 'Head of Investor Relations',\\n                               'unexercisedValue': 0},\\n                              {'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Franz  von Holzhausen',\\n                               'title': 'Chief Designer',\\n                               'unexercisedValue': 0},\\n                              {'age': 61,\\n                               'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. John  Walker',\\n                               'title': 'Vice President of Sales - North '\\n                                        'America',\\n                               'totalPay': 121550,\\n                               'unexercisedValue': 0,\\n                               'yearBorn': 1963},\\n                              {'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Peter  Bannon',\\n                               'title': 'Chip Architect',\\n                               'unexercisedValue': 0},\\n                              {'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Turner  Caldwell',\\n                               'title': 'Engineering Manager',\\n                               'unexercisedValue': 0},\\n                              {'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Rodney D. Westmoreland Jr.',\\n                               'title': 'Director of Construction Management',\\n                               'unexercisedValue': 0},\\n                              {'exercisedValue': 0,\\n                               'fiscalYear': 2024,\\n                               'maxAge': 1,\\n                               'name': 'Mr. Lars  Moravy',\\n                               'title': 'Vice President of Vehicle Engineering',\\n                               'unexercisedValue': 0}],\\n          'compensationAsOfEpochDate': 1735603200,\\n          'compensationRisk': 10,\\n          'corporateActions': [],\\n          'country': 'United States',\\n          'cryptoTradeable': False,\\n          'currency': 'USD',\\n          'currentPrice': 329.5386,\\n          'currentRatio': 2.037,\\n          'customPriceAlertConfidence': 'HIGH',\\n          'dateShortInterest': 1753920000,\\n          'dayHigh': 339.3,\\n          'dayLow': 327.02,\\n          'debtToEquity': 16.823,\\n          'displayName': 'Tesla',\\n          'earningsCallTimestampEnd': 1753306200,\\n          'earningsCallTimestampStart': 1753306200,\\n          'earningsGrowth': -0.175,\\n          'earningsQuarterlyGrowth': -0.163,\\n          'earningsTimestamp': 1753300800,\\n          'earningsTimestampEnd': 1761163200,\\n          'earningsTimestampStart': 1761163200,\\n          'ebitda': 11345999872,\\n          'ebitdaMargins': 0.122370005,\\n          'enterpriseToEbitda': 93.381,\\n          'enterpriseToRevenue': 11.427,\\n          'enterpriseValue': 1059506159616,\\n          'epsCurrentYear': 1.68743,\\n          'epsForward': 3.24,\\n          'epsTrailingTwelveMonths': 1.68,\\n          'esgPopulated': False,\\n          'exchange': 'NMS',\\n          'exchangeDataDelayedBy': 0,\\n          'exchangeTimezoneName': 'America/New_York',\\n          'exchangeTimezoneShortName': 'EDT',\\n          'executiveTeam': [],\\n          'fiftyDayAverage': 319.3578,\\n          'fiftyDayAverageChange': 10.180817,\\n          'fiftyDayAverageChangePercent': 0.03187903,\\n          'fiftyTwoWeekChangePercent': 55.274845,\\n          'fiftyTwoWeekHigh': 488.54,\\n          'fiftyTwoWeekHighChange': -159.0014,\\n          'fiftyTwoWeekHighChangePercent': -0.3254624,\\n          'fiftyTwoWeekLow': 202.59,\\n          'fiftyTwoWeekLowChange': 126.94861,\\n          'fiftyTwoWeekLowChangePercent': 0.6266282,\\n          'fiftyTwoWeekRange': '202.59 - 488.54',\\n          'financialCurrency': 'USD',\\n          'firstTradeDateMilliseconds': 1277818200000,\\n          'floatShares': 2711570372,\\n          'forwardEps': 3.24,\\n          'forwardPE': 101.70944,\\n          'freeCashflow': 1339624960,\\n          'fullExchangeName': 'NasdaqGS',\\n          'fullTimeEmployees': 125665,\\n          'gmtOffSetMilliseconds': -14400000,\\n          'governanceEpochDate': 1754006400,\\n          'grossMargins': 0.1748,\\n          'grossProfits': 16206999552,\\n          'hasPrePostMarketData': True,\\n          'heldPercentInsiders': 0.12875,\\n          'heldPercentInstitutions': 0.50949,\\n          'impliedSharesOutstanding': 3225449984,\\n          'industry': 'Auto Manufacturers',\\n          'industryDisp': 'Auto Manufacturers',\\n          'industryKey': 'auto-manufacturers',\\n          'isEarningsDateEstimate': True,\\n          'language': 'en-US',\\n          'lastFiscalYearEnd': 1735603200,\\n          'lastSplitDate': 1661385600,\\n          'lastSplitFactor': '3:1',\\n          'longBusinessSummary': 'Tesla, Inc. designs, develops, manufactures, '\\n                                 'leases, and sells electric vehicles, and '\\n                                 'energy generation and storage systems in the '\\n                                 'United States, China, and internationally. '\\n                                 'The company operates in two segments, '\\n                                 'Automotive; and Energy Generation and '\\n                                 'Storage. The Automotive segment offers '\\n                                 'electric vehicles, as well as sells '\\n                                 'automotive regulatory credits; and '\\n                                 'non-warranty after-sales vehicle, used '\\n                                 'vehicles, body shop and parts, '\\n                                 'supercharging, retail merchandise, and '\\n                                 'vehicle insurance services. This segment '\\n                                 'also provides sedans and sport utility '\\n                                 'vehicles through direct and used vehicle '\\n                                 'sales, a network of Tesla Superchargers, and '\\n                                 'in-app upgrades; purchase financing and '\\n                                 'leasing services; services for electric '\\n                                 'vehicles through its company-owned service '\\n                                 'locations and Tesla mobile service '\\n                                 'technicians; and vehicle limited warranties '\\n                                 'and extended service plans. The Energy '\\n                                 'Generation and Storage segment engages in '\\n                                 'the design, manufacture, installation, sale, '\\n                                 'and leasing of solar energy generation and '\\n                                 'energy storage products, and related '\\n                                 'services to residential, commercial, and '\\n                                 'industrial customers and utilities through '\\n                                 'its website, stores, and galleries, as well '\\n                                 'as through a network of channel partners. '\\n                                 'This segment also provides services and '\\n                                 'repairs to its energy product customers, '\\n                                 'including under warranty; and various '\\n                                 'financing options to its residential '\\n                                 'customers. The company was formerly known as '\\n                                 'Tesla Motors, Inc. and changed its name to '\\n                                 'Tesla, Inc. in February 2017. Tesla, Inc. '\\n                                 'was incorporated in 2003 and is '\\n                                 'headquartered in Austin, Texas.',\\n          'longName': 'Tesla, Inc.',\\n          'market': 'us_market',\\n          'marketCap': 1062910296064,\\n          'marketState': 'REGULAR',\\n          'maxAge': 86400,\\n          'messageBoardId': 'finmb_27444752',\\n          'mostRecentQuarter': 1751241600,\\n          'netIncomeToCommon': 5879000064,\\n          'nextFiscalYearEnd': 1767139200,\\n          'numberOfAnalystOpinions': 40,\\n          'open': 337.655,\\n          'operatingCashflow': 15765000192,\\n          'operatingMargins': 0.04103,\\n          'overallRisk': 10,\\n          'payoutRatio': 0.0,\\n          'phone': '512 516 8177',\\n          'previousClose': 335.58,\\n          'priceEpsCurrentYear': 195.29024,\\n          'priceHint': 2,\\n          'priceToBook': 13.741653,\\n          'priceToSalesTrailing12Months': 11.463657,\\n          'profitMargins': 0.063439995,\\n          'quickRatio': 1.359,\\n          'quoteSourceName': 'Nasdaq Real Time Price',\\n          'quoteType': 'EQUITY',\\n          'recommendationKey': 'hold',\\n          'recommendationMean': 2.65957,\\n          'region': 'US',\\n          'regularMarketChange': -6.041382,\\n          'regularMarketChangePercent': -1.8001391,\\n          'regularMarketDayHigh': 339.3,\\n          'regularMarketDayLow': 327.02,\\n          'regularMarketDayRange': '327.02 - 339.3',\\n          'regularMarketOpen': 337.655,\\n          'regularMarketPreviousClose': 335.58,\\n          'regularMarketPrice': 329.5386,\\n          'regularMarketTime': 1755282398,\\n          'regularMarketVolume': 55029132,\\n          'returnOnAssets': 0.02911,\\n          'returnOnEquity': 0.08177,\\n          'revenueGrowth': -0.118,\\n          'revenuePerShare': 28.862,\\n          'sector': 'Consumer Cyclical',\\n          'sectorDisp': 'Consumer Cyclical',\\n          'sectorKey': 'consumer-cyclical',\\n          'shareHolderRightsRisk': 9,\\n          'sharesOutstanding': 3225449984,\\n          'sharesPercentSharesOut': 0.0223,\\n          'sharesShort': 71986527,\\n          'sharesShortPreviousMonthDate': 1751241600,\\n          'sharesShortPriorMonth': 80074233,\\n          'shortName': 'Tesla, Inc.',\\n          'shortPercentOfFloat': 0.0256,\\n          'shortRatio': 0.74,\\n          'sourceInterval': 15,\\n          'state': 'TX',\\n          'symbol': 'TSLA',\\n          'targetHighPrice': 500.0,\\n          'targetLowPrice': 115.0,\\n          'targetMeanPrice': 306.32074,\\n          'targetMedianPrice': 322.5,\\n          'totalCash': 36781998080,\\n          'totalCashPerShare': 11.404,\\n          'totalDebt': 13134000128,\\n          'totalRevenue': 92719996928,\\n          'tradeable': False,\\n          'trailingAnnualDividendRate': 0.0,\\n          'trailingAnnualDividendYield': 0.0,\\n          'trailingEps': 1.68,\\n          'trailingPE': 196.15393,\\n          'trailingPegRatio': 6.3254,\\n          'triggerable': True,\\n          'twoHundredDayAverage': 326.2506,\\n          'twoHundredDayAverageChange': 3.2879944,\\n          'twoHundredDayAverageChangePercent': 0.010078125,\\n          'typeDisp': 'Equity',\\n          'volume': 55029132,\\n          'website': 'https://www.tesla.com',\\n          'zip': '78725'},\\n 'stock_symbol': 'TSLA'}\" name='fetch_stock_data_raw' id='0501f44a-7cd0-42ec-a69c-931526250381' tool_call_id='call_R1MQuPOJby5zLEUx25opaWVu'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      4\u001b[39m input_message = HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mShould I invest in Tesla stocks?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m client.runs.stream(\n\u001b[32m      7\u001b[39m             thread[\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m], \n\u001b[32m      8\u001b[39m             assistant_id=\u001b[33m\"\u001b[39m\u001b[33mb7480eb0-6390-53a5-9bc4-29bf27cbd1c4\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      9\u001b[39m             \u001b[38;5;28minput\u001b[39m={\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [input_message]}, \n\u001b[32m     10\u001b[39m             stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     messages = \u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m messages:\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mprint\u001b[39m(convert_to_messages(messages)[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Should I invest in Tesla stocks?\")\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "            thread[\"thread_id\"], \n",
    "            assistant_id=\"b7480eb0-6390-53a5-9bc4-29bf27cbd1c4\", \n",
    "            input={\"messages\": [input_message]}, \n",
    "            stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "\n",
    "# display content only with convert_to_messages util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
