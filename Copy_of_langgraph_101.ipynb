{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenny005/Langgraph-Tutorial/blob/main/Copy_of_langgraph_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc082433",
      "metadata": {
        "id": "dc082433"
      },
      "source": [
        "# LangGraph 101\n",
        "\n",
        "[LLMs](https://python.langchain.com/docs/concepts/chat_models/) make it possible to embed intelligence into a new class of applications. [LangGraph](https://langchain-ai.github.io/langgraph/) is a framework to help build applications with LLMs. Here, we will overview the basics of LangGraph, explain its benefits, show how to use it to build workflows / agents, and show how it works with [LangChain](https://www.langchain.com/) / [LangSmith](https://docs.smith.langchain.com/).\n",
        "\n",
        "![ecosystem](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/ecosystem.png?raw=1)\n",
        "\n",
        "## Chat models\n",
        "\n",
        "[Chat models](https://python.langchain.com/docs/concepts/chat_models/) are the foundation of LLM applications. They are typically accessed through a chat interface that takes a list of [messages](https://python.langchain.com/docs/concepts/messages/) as input and returns a [message](https://python.langchain.com/docs/concepts/messages/) as output. LangChain provides [a standardized interface for chat models](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html), making it easy to [access many different providers](https://python.langchain.com/docs/integrations/chat/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AaHEpkh8oo6I",
        "outputId": "5609cbd2-70fd-492a-a25a-95f0a8f04f62",
        "collapsed": true
      },
      "id": "AaHEpkh8oo6I",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 1)) (4.14.1)\n",
            "Collecting typing (from -r /content/requirements.txt (line 2))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langgraph (from -r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph-0.6.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai (from -r /content/requirements.txt (line 4))\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 5)) (0.3.74)\n",
            "Collecting langgraph-checkpoint-mongodb (from -r /content/requirements.txt (line 6))\n",
            "  Downloading langgraph_checkpoint_mongodb-0.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community (from -r /content/requirements.txt (line 7))\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting python-dotenv (from -r /content/requirements.txt (line 8))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 9)) (0.2.65)\n",
            "Collecting pymongo (from -r /content/requirements.txt (line 10))\n",
            "  Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting wikipedia (from -r /content/requirements.txt (line 11))\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trustcall (from -r /content/requirements.txt (line 12))\n",
            "  Downloading trustcall-0.0.39-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting langchain-mcp-adapters (from -r /content/requirements.txt (line 13))\n",
            "  Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r /content/requirements.txt (line 3)) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r /content/requirements.txt (line 3)) (3.5.0)\n",
            "Collecting openai<2.0.0,>=1.99.9 (from langchain_openai->-r /content/requirements.txt (line 4))\n",
            "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->-r /content/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core->-r /content/requirements.txt (line 5)) (25.0)\n",
            "Collecting langchain-mongodb>=0.6.1 (from langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading langchain_mongodb-0.6.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting motor>3.6.0 (from langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading motor-3.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pymongo (from -r /content/requirements.txt (line 10))\n",
            "  Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r /content/requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance->-r /content/requirements.txt (line 9)) (15.0.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo->-r /content/requirements.txt (line 10))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting dydantic<1.0.0,>=0.0.8 (from trustcall->-r /content/requirements.txt (line 12))\n",
            "  Downloading dydantic-0.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting mcp>=1.9.2 (from langchain-mcp-adapters->-r /content/requirements.txt (line 13))\n",
            "  Downloading mcp-1.13.0-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r /content/requirements.txt (line 7)) (1.20.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r /content/requirements.txt (line 9)) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (2025.8.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r /content/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community->-r /content/requirements.txt (line 7)) (0.3.9)\n",
            "Collecting lark<2.0.0,>=1.1.9 (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb->-r /content/requirements.txt (line 6))\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r /content/requirements.txt (line 3))\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core->-r /content/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core->-r /content/requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (4.25.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13))\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.47.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai->-r /content/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph->-r /content/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r /content/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r /content/requirements.txt (line 7)) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai->-r /content/requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance->-r /content/requirements.txt (line 9)) (2.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r /content/requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance->-r /content/requirements.txt (line 9)) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r /content/requirements.txt (line 7))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain-mcp-adapters->-r /content/requirements.txt (line 13)) (8.2.1)\n",
            "Downloading langgraph-0.6.5-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint_mongodb-0.1.4-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trustcall-0.0.39-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dydantic-0.0.8-py3-none-any.whl (8.6 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langchain_mongodb-0.6.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.13.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.7.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: typing, wikipedia\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=c0c360450ac372b678125311a97e8e8e9496d5fa67fadf2ca0f4ee3101b0a58d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=bf99a8c4cb9bf198fc63d63eb88a58542ffd88cf24f365cdd200e84d94f72c7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built typing wikipedia\n",
            "Installing collected packages: typing, python-dotenv, ormsgpack, mypy-extensions, marshmallow, lark, httpx-sse, dnspython, wikipedia, typing-inspect, sse-starlette, pymongo, pydantic-settings, openai, motor, langgraph-sdk, dydantic, dataclasses-json, mcp, langgraph-checkpoint, langchain_openai, langchain-mcp-adapters, langgraph-prebuilt, langgraph, langchain-mongodb, langchain_community, trustcall, langgraph-checkpoint-mongodb\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.8\n",
            "    Uninstalling openai-1.99.8:\n",
            "      Successfully uninstalled openai-1.99.8\n",
            "Successfully installed dataclasses-json-0.6.7 dnspython-2.7.0 dydantic-0.0.8 httpx-sse-0.4.1 langchain-mcp-adapters-0.1.9 langchain-mongodb-0.6.2 langchain_community-0.3.27 langchain_openai-0.3.30 langgraph-0.6.5 langgraph-checkpoint-2.1.1 langgraph-checkpoint-mongodb-0.1.4 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 lark-1.2.2 marshmallow-3.26.1 mcp-1.13.0 motor-3.7.1 mypy-extensions-1.1.0 openai-1.99.9 ormsgpack-1.10.0 pydantic-settings-2.10.1 pymongo-4.12.1 python-dotenv-1.1.1 sse-starlette-3.0.2 trustcall-0.0.39 typing-3.7.4.3 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "a9092d4398df46c496b2302868658751"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cecc2b24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cecc2b24",
        "outputId": "e99768f4-44dc-4ae4-d037-ca5c34a6457f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from dotenv import load_dotenv  # load environment variables from a .env file into your program’s os.environ dictionary\n",
        "load_dotenv(\"/content/.env\", override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e0ee8f6c",
      "metadata": {
        "id": "e0ee8f6c"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50777b0b",
      "metadata": {
        "id": "50777b0b"
      },
      "source": [
        "## Running the model\n",
        "\n",
        "The `init_chat_model` interface provides [standardized](https://python.langchain.com/docs/concepts/runnables/) methods for using chat models, which include:\n",
        "- `invoke()`: A single input is transformed into an output.\n",
        "- `stream()`: Outputs are [streamed](https://python.langchain.com/docs/concepts/streaming/#stream-and-astream) as they are produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a28159d5",
      "metadata": {
        "id": "a28159d5"
      },
      "outputs": [],
      "source": [
        "result = llm.invoke(\"What is an agent?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "41137023",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "41137023",
        "outputId": "ffd7e4f4-a6b0-4d09-c48e-ec8b45259a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 154);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc1d00eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "dc1d00eb",
        "outputId": "3a6087b7-94d3-4d3d-e6fd-a2d9f3dc86a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The term \u001b[1m\"agent\"\u001b[0m can have different meanings depending on the context. Here are some common definitions:           \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "                                               \u001b[1m1. \u001b[0m\u001b[1mGeneral Definition\u001b[0m                                               \n",
              "\n",
              "An \u001b[1magent\u001b[0m is \u001b[1msomeone or something that acts on behalf of another\u001b[0m or \u001b[1mcauses an effect\u001b[0m.                               \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "                                              \u001b[1m2. \u001b[0m\u001b[1mIn Everyday Language\u001b[0m                                              \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mA person who acts on behalf of another:\u001b[0m                                                                         \n",
              "\u001b[1;33m   \u001b[0mFor example, a real estate agent helps people buy or sell houses.                                               \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mA representative:\u001b[0m                                                                                               \n",
              "\u001b[1;33m   \u001b[0mSuch as a travel agent, sports agent, or insurance agent.                                                       \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "                                                   \u001b[1m3. \u001b[0m\u001b[1mIn Science\u001b[0m                                                   \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mA substance that produces an effect:\u001b[0m                                                                            \n",
              "\u001b[1;33m   \u001b[0mFor example, a cleaning agent (like soap), or a biological agent (like a virus or bacteria).                    \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "                                 \u001b[1m4. \u001b[0m\u001b[1mIn Computer Science & Artificial Intelligence\u001b[0m                                  \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAn agent is an entity that perceives its environment and takes actions to achieve goals.\u001b[0m                        \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mSoftware agent:\u001b[0m A program that performs tasks autonomously (e.g., a chatbot, a web crawler).                 \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mAI agent:\u001b[0m A system that senses and acts in an environment (e.g., a robot, a self-driving car).               \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "                                                 \u001b[1m5. \u001b[0m\u001b[1mIn Philosophy\u001b[0m                                                  \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAn agent is an entity capable of action and making choices.\u001b[0m                                                     \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "\u001b[1mSummary:\u001b[0m                                                                                                           \n",
              "An \u001b[1magent\u001b[0m is generally \u001b[1msomeone or something that acts, does something, or causes something to happen, often on \u001b[0m     \n",
              "\u001b[1mbehalf of someone else or to achieve a goal\u001b[0m. The specific meaning depends on the context in which the word is used.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The term <span style=\"font-weight: bold\">\"agent\"</span> can have different meanings depending on the context. Here are some common definitions:           \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "                                               <span style=\"font-weight: bold\">1. General Definition</span>                                               \n",
              "\n",
              "An <span style=\"font-weight: bold\">agent</span> is <span style=\"font-weight: bold\">someone or something that acts on behalf of another</span> or <span style=\"font-weight: bold\">causes an effect</span>.                               \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "                                              <span style=\"font-weight: bold\">2. In Everyday Language</span>                                              \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">A person who acts on behalf of another:</span>                                                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>For example, a real estate agent helps people buy or sell houses.                                               \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">A representative:</span>                                                                                               \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Such as a travel agent, sports agent, or insurance agent.                                                       \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "                                                   <span style=\"font-weight: bold\">3. In Science</span>                                                   \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">A substance that produces an effect:</span>                                                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>For example, a cleaning agent (like soap), or a biological agent (like a virus or bacteria).                    \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "                                 <span style=\"font-weight: bold\">4. In Computer Science &amp; Artificial Intelligence</span>                                  \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">An agent is an entity that perceives its environment and takes actions to achieve goals.</span>                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Software agent:</span> A program that performs tasks autonomously (e.g., a chatbot, a web crawler).                 \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">AI agent:</span> A system that senses and acts in an environment (e.g., a robot, a self-driving car).               \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "                                                 <span style=\"font-weight: bold\">5. In Philosophy</span>                                                  \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">An agent is an entity capable of action and making choices.</span>                                                     \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "<span style=\"font-weight: bold\">Summary:</span>                                                                                                           \n",
              "An <span style=\"font-weight: bold\">agent</span> is generally <span style=\"font-weight: bold\">someone or something that acts, does something, or causes something to happen, often on </span>     \n",
              "<span style=\"font-weight: bold\">behalf of someone else or to achieve a goal</span>. The specific meaning depends on the context in which the word is used.\n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from rich.markdown import Markdown\n",
        "Markdown(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a24d8ef",
      "metadata": {
        "id": "9a24d8ef"
      },
      "source": [
        "## Tools\n",
        "\n",
        "[Tools](https://python.langchain.com/docs/concepts/tools/) are utilities that can be called by a chat model. In LangChain, creating tools can be done using the `@tool` decorator, which transforms Python functions into callable tools. It will automatically infer the tool's name, description, and expected arguments from the function definition. You can also use [Model Context Protocol (MCP) servers](https://github.com/langchain-ai/langchain-mcp-adapters) as LangChain-compatible tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "afdff275",
      "metadata": {
        "id": "afdff275"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def write_email(to: str, subject: str, content: str) -> str:\n",
        "    \"\"\"Write and send an email.\"\"\"\n",
        "    # Placeholder response - in real app would send email\n",
        "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c52ec55b-0b60-4b0c-95d4-ff528a64694e",
      "metadata": {
        "id": "c52ec55b-0b60-4b0c-95d4-ff528a64694e",
        "outputId": "db631cd7-bbc5-4504-cf6c-9fa045a2a73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.tools.structured.StructuredTool"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.tools.structured.StructuredTool</b><br/>def warning_emitting_wrapper(*args: Any, **kwargs: Any) -&gt; Any</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py</a>Tool that can operate on any number of inputs.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 39);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(write_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "23a40647-3d48-4760-aabe-144d627de110",
      "metadata": {
        "id": "23a40647-3d48-4760-aabe-144d627de110",
        "outputId": "79afb45d-cfe2-4437-9270-f6e8bb27cbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': {'title': 'To', 'type': 'string'},\n",
              " 'subject': {'title': 'Subject', 'type': 'string'},\n",
              " 'content': {'title': 'Content', 'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "write_email.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "abd85ae4-9d4c-4efa-9577-aca96e9f22cd",
      "metadata": {
        "id": "abd85ae4-9d4c-4efa-9577-aca96e9f22cd",
        "outputId": "e58dee9b-fdba-4071-b562-671d5b9e834d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Write and send an email.                                                                                           \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Write and send an email.                                                                                           \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Markdown(write_email.description)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a6b427",
      "metadata": {
        "id": "c8a6b427"
      },
      "source": [
        "## Tool Calling\n",
        "\n",
        "Tools can be [called](https://python.langchain.com/docs/concepts/tool_calling/) by LLMs. When a tool is bound to the model, the model can choose to call the tool by returning a structured output with tool arguments. We use the `bind_tools` method to augment an LLM with tools.\n",
        "\n",
        "![tool-img](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/tool_call_detail.png?raw=1)\n",
        "\n",
        "Providers often have [parameters such as `tool_choice`](https://python.langchain.com/docs/how_to/tool_choice/) to enforce calling specific tools. `any` will select at least one of the tools.\n",
        "\n",
        "In addition, we can [set `parallel_tool_calls=False`](https://python.langchain.com/docs/how_to/tool_calling_parallel/) to ensure the model will only call one tool at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bfa57bc4",
      "metadata": {
        "id": "bfa57bc4"
      },
      "outputs": [],
      "source": [
        "# Connect tools to a chat model\n",
        "model_with_tools = llm.bind_tools([write_email], tool_choice=\"any\", parallel_tool_calls=False)\n",
        "\n",
        "# The model will now be able to call tools\n",
        "output = model_with_tools.invoke(\"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7985eab6-9e6b-4fa5-8027-52d32886b97e",
      "metadata": {
        "id": "7985eab6-9e6b-4fa5-8027-52d32886b97e",
        "outputId": "84543340-845d-47fa-b03e-c0706d8b7b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 154);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ea0ce030-e760-4679-838f-d88d1480664e",
      "metadata": {
        "id": "ea0ce030-e760-4679-838f-d88d1480664e",
        "outputId": "c886aef1-e57f-4bf7-cb34-45c745ed78f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qA97aCrm7MRcxkIAAgkprGMJ', 'function': {'arguments': '{\"to\":\"boss@company.ai\",\"subject\":\"Re: Tomorrow\\'s Meeting\",\"content\":\"Hello,\\\\n\\\\nThank you for the reminder about tomorrow\\'s meeting. I will be there and am looking forward to discussing our agenda. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\\\n\\\\nBest regards,\\\\n[Your Name]\"}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 67, 'total_tokens': 153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'id': 'chatcmpl-C4oGAhmqZ4qYH2dIsgBBK3ITCoM3G', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ae496cb3-46e3-42bb-bd41-0c12061fc0f0-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'boss@company.ai', 'subject': \"Re: Tomorrow's Meeting\", 'content': \"Hello,\\n\\nThank you for the reminder about tomorrow's meeting. I will be there and am looking forward to discussing our agenda. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\n\\nBest regards,\\n[Your Name]\"}, 'id': 'call_qA97aCrm7MRcxkIAAgkprGMJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 67, 'output_tokens': 86, 'total_tokens': 153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "717779cb",
      "metadata": {
        "id": "717779cb",
        "outputId": "bd355938-d704-4a69-8a6c-51dbd9e25ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': 'boss@company.ai',\n",
              " 'subject': \"Re: Tomorrow's Meeting\",\n",
              " 'content': \"Hello,\\n\\nThank you for the reminder about tomorrow's meeting. I will be there and am looking forward to discussing our agenda. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\n\\nBest regards,\\n[Your Name]\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Extract tool calls and execute them\n",
        "args = output.tool_calls[0]['args']\n",
        "args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "09f85694",
      "metadata": {
        "id": "09f85694",
        "outputId": "2df74102-286d-4533-ea0b-2bdf6964e1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Hello,                            \n",
              "\n",
              "Thank you for the reminder about tomorrow's meeting. I will be there and am looking forward to discussing our      \n",
              "agenda. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.     \n",
              "\n",
              "Best regards, [Your Name]                                                                                          \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Hello,                            \n",
              "\n",
              "Thank you for the reminder about tomorrow's meeting. I will be there and am looking forward to discussing our      \n",
              "agenda. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.     \n",
              "\n",
              "Best regards, [Your Name]                                                                                          \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Call the tool\n",
        "result = write_email.invoke(args)\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f9c52a",
      "metadata": {
        "id": "b6f9c52a"
      },
      "source": [
        "![basic_prompt](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/tool_call.png?raw=1)\n",
        "\n",
        "## Workflows\n",
        "\n",
        "There are many patterns for building applications with LLMs.\n",
        "\n",
        "[We can embed LLM calls into pre-defined workflows](https://langchain-ai.github.io/langgraph/tutorials/workflows/), giving the system more agency to make decisions.\n",
        "\n",
        "As an example, we could add a router step to determine whether to write an email or not.\n",
        "\n",
        "![workflow_example](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/workflow_example.png?raw=1)\n",
        "\n",
        "## Agents\n",
        "\n",
        "We can further increase agency, allowing the LLM to dynamically direct its own tool usage.\n",
        "\n",
        "[Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/#agent) are typically implemented as tool calling in a loop, where the output of each tool call is used to inform the next action.\n",
        "\n",
        "![agent_example](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/agent_example.png?raw=1)\n",
        "\n",
        "Agents are well suited to open-ended problems where it's difficult to predict the *exact* steps needed in advance.\n",
        "\n",
        "Workflows are often appropriate when the control flow can easily be defined in advance.\n",
        "\n",
        "![workflow_v_agent](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/workflow_v_agent.png?raw=1)\n",
        "\n",
        "## What is LangGraph?\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) provides low-level supporting infrastructure that sits underneath *any* workflow or agent.\n",
        "\n",
        "It does not abstract prompts or architecture, and provides a few benefits:\n",
        "\n",
        "- **Control**: Make it easy to define and / or combine agents and workflows.\n",
        "- **Persistence**: Provide a way to persist the state of a graph, which enables both memory and human-in-the-loop.\n",
        "- **Testing, Debugging, and Deployment**: Provide an easy onramp for testing, debugging, and deploying applications.\n",
        "\n",
        "### Control\n",
        "\n",
        "LangGraph lets you define your application as a graph with:\n",
        "\n",
        "1. *State*: What information do we need to track over the course of the application?\n",
        "2. *Nodes*: How do we want to update this information over the course of the application?\n",
        "3. *Edges*: How do we want to connect these nodes together?\n",
        "\n",
        "We can use the [`StateGraph` class](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs) to initialize a LangGraph graph with a [`State` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state).\n",
        "\n",
        "`State` defines the schema for information we want to track over the course of the application.\n",
        "\n",
        "This can be any object with `getattr()` in python, such as a dictionary, dataclass, or Pydantic object:\n",
        "\n",
        "- TypeDict is fastest but doesn’t support defaults\n",
        "- Dataclass is basically as fast, supports dot syntax `state.foo`, and has defaults.\n",
        "- Pydantic is slower (especially with custom validators) but gives type validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3319290a",
      "metadata": {
        "id": "3319290a"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "class StateSchema(TypedDict):\n",
        "    request: str\n",
        "    email: str\n",
        "\n",
        "workflow = StateGraph(StateSchema)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b84bedb9",
      "metadata": {
        "id": "b84bedb9"
      },
      "source": [
        "Each node is simply a python function or typescript code. This gives us full control over the logic inside each node.\n",
        "\n",
        "They receive the current state, and return a dictionary to update the state.\n",
        "\n",
        "By default, [state keys are overwritten](https://langchain-ai.github.io/langgraph/how-tos/state-reducers/).\n",
        "\n",
        "However, you can [define custom update logic](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers).\n",
        "\n",
        "![nodes_edges](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/nodes_edges.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d5e79c1f",
      "metadata": {
        "id": "d5e79c1f"
      },
      "outputs": [],
      "source": [
        "def write_email_node(state: StateSchema) -> StateSchema:\n",
        "    # Imperative code that processes the request\n",
        "    output = model_with_tools.invoke(state[\"request\"])\n",
        "    args = output.tool_calls[0]['args']\n",
        "    email = write_email.invoke(args)\n",
        "    return {\"email\": email}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "737c8040",
      "metadata": {
        "id": "737c8040"
      },
      "source": [
        "Edges connect nodes together.\n",
        "\n",
        "We specify the control flow by adding edges and nodes to our state graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "554e0d8b",
      "metadata": {
        "id": "554e0d8b"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(StateSchema)\n",
        "workflow.add_node(\"write_email_node\", write_email_node)\n",
        "workflow.add_edge(START, \"write_email_node\")\n",
        "workflow.add_edge(\"write_email_node\", END)\n",
        "\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7cc79b40",
      "metadata": {
        "id": "7cc79b40",
        "outputId": "9cb1afd7-f9b0-44cf-cb45-02a5b635c0ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'request': \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\",\n",
              " 'email': \"Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Hello,\\n\\nThank you for the reminder about tomorrow's meeting. I confirm my attendance and will be prepared with the necessary updates and materials.\\n\\nPlease let me know if there is anything specific you would like me to focus on or bring to the discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "app.invoke({\"request\": \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2446dea9",
      "metadata": {
        "id": "2446dea9"
      },
      "source": [
        "Routing between nodes can be done [conditionally](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges) using a simple function.\n",
        "\n",
        "The return value of this function is used as the name of the node (or list of nodes) to send the state to next.\n",
        "\n",
        "You can optionally provide a dictionary that maps the `should_continue` output to the name of the next node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f29b05bf",
      "metadata": {
        "id": "f29b05bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "f513fd25-061a-478f-e417-323b416015d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Literal\n",
        "from langgraph.graph import MessagesState\n",
        "#from email_assistant.utils import show_graph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def call_llm(state: MessagesState) -> MessagesState:\n",
        "    \"\"\"Run LLM\"\"\"\n",
        "\n",
        "    output = model_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [output]}\n",
        "\n",
        "def run_tool(state: MessagesState):\n",
        "    \"\"\"Performs the tool call\"\"\"\n",
        "\n",
        "    result = []\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        observation = write_email.invoke(tool_call[\"args\"])\n",
        "        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
        "    return {\"messages\": result}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"run_tool\", \"__end__\"]:\n",
        "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
        "\n",
        "    # Get the last message\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    # If the last message is a tool call, check if it's a Done tool call\n",
        "    if last_message.tool_calls:\n",
        "        return \"run_tool\"\n",
        "    # Otherwise, we stop (reply to the user)\n",
        "    return END\n",
        "\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"call_llm\", call_llm)\n",
        "workflow.add_node(\"run_tool\", run_tool)\n",
        "workflow.add_edge(START, \"call_llm\")\n",
        "workflow.add_conditional_edges(\"call_llm\", should_continue, {\"run_tool\": \"run_tool\", END: END})\n",
        "workflow.add_edge(\"run_tool\", END)\n",
        "\n",
        "# Run the workflow\n",
        "app = workflow.compile()\n",
        "\n",
        "# Show\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dadbafde",
      "metadata": {
        "id": "dadbafde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77c57bb-6cb8-48f2-9b6a-2cd68e2f50d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  write_email (call_cTtcbtqeixXtfBkji2KtUxAc)\n",
            " Call ID: call_cTtcbtqeixXtfBkji2KtUxAc\n",
            "  Args:\n",
            "    to: boss@company.ai\n",
            "    subject: Confirmation: Attendance at Interrupt!\n",
            "    content: Hi,\n",
            "\n",
            "Thank you for letting me know about Interrupt! I would like to confirm that I am interested in attending the event.\n",
            "\n",
            "Please let me know if there are any next steps or additional details I should be aware of.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "Email sent to boss@company.ai with subject 'Confirmation: Attendance at Interrupt!' and content: Hi,\n",
            "\n",
            "Thank you for letting me know about Interrupt! I would like to confirm that I am interested in attending the event.\n",
            "\n",
            "Please let me know if there are any next steps or additional details I should be aware of.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]\n"
          ]
        }
      ],
      "source": [
        "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]})\n",
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78b232d",
      "metadata": {
        "id": "a78b232d"
      },
      "source": [
        "With these low level components, you can build many many different workflows and agents. See [this tutorial](https://langchain-ai.github.io/langgraph/tutorials/workflows/)!\n",
        "\n",
        "Because agents are such a common pattern, [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built) has [a pre-built agent](https://langchain-ai.github.io/langgraph/agents/overview/?ref=blog.langchain.dev#what-is-an-agent) abstraction.\n",
        "\n",
        "With LangGraph's [pre-built method](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built), we just pass in the LLM, tools, and prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5a317ad8",
      "metadata": {
        "id": "5a317ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a69ddf-5d64-471e-d3ce-9ea86ca154ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  write_email (call_jiQ0kRP5QzwCuBBXGC3pJvig)\n",
            " Call ID: call_jiQ0kRP5QzwCuBBXGC3pJvig\n",
            "  Args:\n",
            "    to: boss@company.ai\n",
            "    subject: Confirmation: Attendance at Interrupt!\n",
            "    content: Hi,\n",
            "\n",
            "Thank you for the opportunity. I am confirming that I would like to attend Interrupt! Please let me know if there are any next steps or additional information needed from my side.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: write_email\n",
            "\n",
            "Email sent to boss@company.ai with subject 'Confirmation: Attendance at Interrupt!' and content: Hi,\n",
            "\n",
            "Thank you for the opportunity. I am confirming that I would like to attend Interrupt! Please let me know if there are any next steps or additional information needed from my side.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've drafted and sent a response to your boss confirming that you want to attend Interrupt! If you need to add any specific details or make changes, let me know.\n"
          ]
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[write_email],\n",
        "    prompt=\"Respond to the user's request using the tools provided.\"\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]}\n",
        ")\n",
        "\n",
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6e506f",
      "metadata": {
        "id": "3c6e506f"
      },
      "source": [
        "### Persistence\n",
        "\n",
        "#### Threads\n",
        "\n",
        "It can be very useful to allow agents to pause during long running tasks.\n",
        "\n",
        "LangGraph has a built-in persistence layer, implemented through checkpointers, to enable this.\n",
        "\n",
        "When you compile graph with a checkpointer, the checkpointer saves a [checkpoint](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) of the graph state at every step.\n",
        "\n",
        "Checkpoints are saved to a thread, which can be accessed after graph execution completes.\n",
        "\n",
        "![checkpointer](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/checkpoints.png?raw=1)\n",
        "\n",
        "We compile the graph with a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9a72377e",
      "metadata": {
        "id": "9a72377e"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[write_email],\n",
        "    prompt=\"Respond to the user's request using the tools provided.\",\n",
        "    checkpointer=InMemorySaver()\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are some good practices for writing emails?\"}]}, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "10984007",
      "metadata": {
        "id": "10984007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c5a9c6-5328-4186-a1aa-c260e602d68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are some good practices for writing emails?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are some good practices for writing effective emails:\n",
            "\n",
            "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
            "\n",
            "2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\n",
            "\n",
            "3. **Be Concise and Direct:** Get to the point quickly. Use short paragraphs and avoid unnecessary details.\n",
            "\n",
            "4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it’s free of errors.\n",
            "\n",
            "5. **Be Polite and Professional:** Use courteous language and maintain a professional tone, even if the email is informal.\n",
            "\n",
            "6. **Structure Your Email:** Use paragraphs, bullet points, or numbered lists to organize information clearly.\n",
            "\n",
            "7. **State Your Purpose Early:** Let the recipient know why you’re writing within the first few sentences.\n",
            "\n",
            "8. **Include a Call to Action:** If you need a response or action, state it clearly.\n",
            "\n",
            "9. **Sign Off Properly:** End with a polite closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\n",
            "\n",
            "10. **Use a Professional Signature:** Include your contact information and job title if appropriate.\n",
            "\n",
            "11. **Reply Promptly:** Respond to emails in a timely manner to show respect for the sender’s time.\n",
            "\n",
            "12. **Be Mindful of Tone:** Without body language, written words can be misinterpreted. Read your email aloud to check the tone.\n",
            "\n",
            "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n"
          ]
        }
      ],
      "source": [
        "# Get the latest state snapshot\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "state = agent.get_state(config)\n",
        "for message in state.values['messages']:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7f23ac58",
      "metadata": {
        "id": "7f23ac58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18ccd6a-aa00-43fc-cc98-924f9d3e6d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are some good practices for writing emails?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are some good practices for writing effective emails:\n",
            "\n",
            "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
            "\n",
            "2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\n",
            "\n",
            "3. **Be Concise and Direct:** Get to the point quickly. Use short paragraphs and avoid unnecessary details.\n",
            "\n",
            "4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it’s free of errors.\n",
            "\n",
            "5. **Be Polite and Professional:** Use courteous language and maintain a professional tone, even if the email is informal.\n",
            "\n",
            "6. **Structure Your Email:** Use paragraphs, bullet points, or numbered lists to organize information clearly.\n",
            "\n",
            "7. **State Your Purpose Early:** Let the recipient know why you’re writing within the first few sentences.\n",
            "\n",
            "8. **Include a Call to Action:** If you need a response or action, state it clearly.\n",
            "\n",
            "9. **Sign Off Properly:** End with a polite closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\n",
            "\n",
            "10. **Use a Professional Signature:** Include your contact information and job title if appropriate.\n",
            "\n",
            "11. **Reply Promptly:** Respond to emails in a timely manner to show respect for the sender’s time.\n",
            "\n",
            "12. **Be Mindful of Tone:** Without body language, written words can be misinterpreted. Read your email aloud to check the tone.\n",
            "\n",
            "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Certainly! Here’s a concise and direct email you can send to your boss to confirm your interest in attending Interrupt:\n",
            "\n",
            "---\n",
            "\n",
            "Subject: Confirmation: Attendance at Interrupt\n",
            "\n",
            "Hello [Boss’s Name],\n",
            "\n",
            "Thank you for considering me for the Interrupt event. I would like to confirm that I am interested in attending and look forward to participating.\n",
            "\n",
            "Please let me know if there are any next steps or additional information needed from my end.\n",
            "\n",
            "Best regards,  \n",
            "[Your Name]\n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you’d like to personalize it further or add any specific details!\n"
          ]
        }
      ],
      "source": [
        "# Continue the conversation\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\"}]}, config)\n",
        "for m in result['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5f09fe50",
      "metadata": {
        "id": "5f09fe50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6159079-3b24-4a67-c076-17d236b36ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are some good practices for writing emails?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are some good practices for writing effective emails:\n",
            "\n",
            "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
            "\n",
            "2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\n",
            "\n",
            "3. **Be Concise and Direct:** Get to the point quickly. Use short paragraphs and avoid unnecessary details.\n",
            "\n",
            "4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it’s free of errors.\n",
            "\n",
            "5. **Be Polite and Professional:** Use courteous language and maintain a professional tone, even if the email is informal.\n",
            "\n",
            "6. **Structure Your Email:** Use paragraphs, bullet points, or numbered lists to organize information clearly.\n",
            "\n",
            "7. **State Your Purpose Early:** Let the recipient know why you’re writing within the first few sentences.\n",
            "\n",
            "8. **Include a Call to Action:** If you need a response or action, state it clearly.\n",
            "\n",
            "9. **Sign Off Properly:** End with a polite closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\n",
            "\n",
            "10. **Use a Professional Signature:** Include your contact information and job title if appropriate.\n",
            "\n",
            "11. **Reply Promptly:** Respond to emails in a timely manner to show respect for the sender’s time.\n",
            "\n",
            "12. **Be Mindful of Tone:** Without body language, written words can be misinterpreted. Read your email aloud to check the tone.\n",
            "\n",
            "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Certainly! Here’s a concise and direct email you can send to your boss to confirm your interest in attending Interrupt:\n",
            "\n",
            "---\n",
            "\n",
            "Subject: Confirmation: Attendance at Interrupt\n",
            "\n",
            "Hello [Boss’s Name],\n",
            "\n",
            "Thank you for considering me for the Interrupt event. I would like to confirm that I am interested in attending and look forward to participating.\n",
            "\n",
            "Please let me know if there are any next steps or additional information needed from my end.\n",
            "\n",
            "Best regards,  \n",
            "[Your Name]\n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you’d like to personalize it further or add any specific details!\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I like this, let's write the email to boss@company.ai\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  write_email (call_Ift4SjuihXm95LvXWZtpVWcb)\n",
            " Call ID: call_Ift4SjuihXm95LvXWZtpVWcb\n",
            "  Args:\n",
            "    to: boss@company.ai\n",
            "    subject: Confirmation: Attendance at Interrupt\n",
            "    content: Hello,\n",
            "\n",
            "Thank you for considering me for the Interrupt event. I would like to confirm that I am interested in attending and look forward to participating.\n",
            "\n",
            "Please let me know if there are any next steps or additional information needed from my end.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: write_email\n",
            "\n",
            "Email sent to boss@company.ai with subject 'Confirmation: Attendance at Interrupt' and content: Hello,\n",
            "\n",
            "Thank you for considering me for the Interrupt event. I would like to confirm that I am interested in attending and look forward to participating.\n",
            "\n",
            "Please let me know if there are any next steps or additional information needed from my end.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The email has been prepared and sent to boss@company.ai with your confirmation to attend Interrupt. If you’d like to personalize it further or need help with any follow-up, just let me know!\n"
          ]
        }
      ],
      "source": [
        "# Continue the conversation\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I like this, let's write the email to boss@company.ai\"}]}, config)\n",
        "for m in result['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae8a5d2-cf8a-4465-8d1b-96bb6c6276cf",
      "metadata": {
        "id": "4ae8a5d2-cf8a-4465-8d1b-96bb6c6276cf"
      },
      "source": [
        "#### Interrupts\n",
        "\n",
        "In LangGraph, we can also use [interrupts](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/) to stop graph execution at specific points.\n",
        "\n",
        "Often this is used to collect input from a user and continue execution with collected input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "52c17b60-9474-49a5-b4a1-583b0dc8bba7",
      "metadata": {
        "id": "52c17b60-9474-49a5-b4a1-583b0dc8bba7"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "from langgraph.types import Command, interrupt\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    user_feedback: str\n",
        "\n",
        "def step_1(state):\n",
        "    print(\"---Step 1---\")\n",
        "    pass\n",
        "\n",
        "def human_feedback(state):\n",
        "    print(\"---human_feedback---\")\n",
        "    feedback = interrupt(\"Please provide feedback:\")\n",
        "    return {\"user_feedback\": feedback}\n",
        "\n",
        "def step_3(state):\n",
        "    print(\"---Step 3---\")\n",
        "    pass\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"step_1\", step_1)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_node(\"step_3\", step_3)\n",
        "builder.add_edge(START, \"step_1\")\n",
        "builder.add_edge(\"step_1\", \"human_feedback\")\n",
        "builder.add_edge(\"human_feedback\", \"step_3\")\n",
        "builder.add_edge(\"step_3\", END)\n",
        "\n",
        "# Set up memory\n",
        "memory = InMemorySaver()\n",
        "\n",
        "# Add\n",
        "graph = builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "57c94cb7-067c-4bc5-be33-b615d8e5775e",
      "metadata": {
        "scrolled": true,
        "id": "57c94cb7-067c-4bc5-be33-b615d8e5775e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "5c6d255e-b6d4-4763-9bf9-87cdc954160f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAGwCAIAAABdGdKfAAAAAXNSR0IArs4c6QAAIABJREFUeJztnWdAFMfDh+d6BY6j9w42BJWiRjGKJbYoigkqatTYYgmxlxiNRk2MscQSbIkif2M0GCyxF+yNKM0KCChwdDjujut374fzPVEPQhL2ZmHm+bS3Zfa3PMzu7O7sLkWv1wMMklBhB8BAA7tHF+weXbB7dMHu0QW7Rxc67ACNoVHryguVslptnUSj0+hVyhZwOsriUGkMCs+CzrWgOXiwYcdpDAoJz++VCu3TVElelqw4V2HnyuJZ0rgWdCs7hkqugx3t72FyqNUlKplEQ6NTCh7XebXneXfk+QVbwM5lAtK5v32qMv+RzMmT49WB596GCzvOf0Kt1OU9lBU8kr14Ku8+1KZtmCXsRG9AIvfZaZLziaWh/YWh/YWwszQzdRLNzROVVWWqAbGOVrYM2HFeQRb3t05WKuq0ESPsaHQK7CxEUVOuOr6z+L0PbX068mFnAWRxf/NkBZNNDenb2qq7SU79LAqKELj4cmAHIcE53pn9JQwmBRHxAIBBk5wepFRn3RDDDgLbfer5KitbRmh/G7gxzMyQT52fpEpEeXK4MWC6L3gsk9Vquw1GS7yB6M9d75ypUilgnrXCdH/1aEVQhBXEAHDx68S/nlwBMQA09w9vi118OAI7JqwA0Gnf1aooV15TroIVAJr73HTpe8NQ3NvXp2eUbeZ1aI0+OO6LcuUalZ7FoUFZO3nwaMtNv4qY+7xMmVcgz8wrXbx48bFjx/7Fgv369SsqKiIgEaBQKJ7tuXlZMiIK/1vguK8UKc1/bevRo0f/YimRSFRdXU1AnFf4deIX5dYRV34jQLiup9frt8/NnbXJl6Dyb9y4kZCQ8PDhQ1tb26CgoNmzZ9va2oaEhBim8vn8lJQUqVSamJh469at3NxcW1vbXr16zZgxg81mAwAWLlxIo9GcnJwSEhKmTZu2c+dOw4K9evX64Ycfmj1tca781qnKkbNdm73kv0dvdqRi9d7lzwkq/PHjx126dNm9e7dIJLpx40ZMTMzMmTP1er1CoejSpUtycrJhtt27d4eHh58/f/7evXuXLl0aOHDgli1bDJOWLl0aHR09e/bsK1euVFVVXbt2rUuXLoWFhQQFri5TJnyTT1DhjQOh70ZdrZZrSVQrLy0tjc1mT5o0iUqlOjo6tmvXLicn593ZYmNjIyMjvby8DD/T09Nv3rw5Z84cwzG4uLj4wIEDht0A0fCs6DKxxgwrehcI7rU6PZtLlPvg4GCFQhEXFxceHh4REeHm5mbc29eHwWDcunVrxYoVz54902g0AACh8PUNBS8vL/OIBwBQaRQWl6rX6ykUc9/AhNDW41nQasrVBBXepk2bH3/80c7ObuvWrVFRUZ999ll6evq7s23dunXXrl1RUVHJycmpqakTJ06sP5XFYhEU711kYg2VSjG/eDjuuRb0OgmBe7nu3bsvX778xIkTK1euFIvFcXFxhpptRK/XJyUlffzxx1FRUY6OjgAAiURCXJ7GIfQI2DgQ3NPoFDc/rlymJaLwv/766+bNmwAAOzu7IUOGzJs3TyKRiESi+vOo1Wq5XG5vb2/4qVKprl69SkSYpiCXaR094XTphHN+z7OiP8+UElFyenr6woULjx49Wl1dnZWVdejQITs7OycnJxaLZW9vf/v27dTUVCqV6unpefz48cLCwpqamlWrVgUHB9fW1spkJq6xeHp6AgDOnz+flZVFRODs+xJ7N5TcewXy8jIJuZgVGxsbFRW1YcOGfv36TZ06lcfj7dq1i06nAwAmTZp07969efPmyeXytWvXstns6Ojo4cOHh4WFzZo1i81m9+3bt7i4+K0CXV1dhw4dGh8fv3XrViIC52XJvDqY+xKnATh9tvR6/dFtRSNmuUBp45CH4jz54zu1kTEOUNYOp95TKBT3AO6d01VQ1k4ebp2ohNhxG9pzOaH9hTsX5XaOtGayTP//9evXT602cSqo1WqpVGpDO4zk5GSBQNDcYYHhqlFcXJzJSSqVisFgmIzk7e39888/m1wq76GMxaE6e0PrtAmzn+7jO7WSGnXYANN38f/deZeFBYFPwDQUSalUNnRJgEKh8Pmm71qd2S8K7S+0cTLftYS3gNxH+8KvpS7enLbh5HpgxQyc/1+pmz+nTSjMDYfcT7fvaIeM6+IXT+HcwIbFjePlHD4Nrnj49d7Asfiijj0EsE51zMzNExV8a3rHHoQ0Sv4R8J/NAAAMm+7y8Lb4QQqBXSRIwp97RQwWlQziyVLvDdw7V/XknqT7UBuSPK7WvDy4XP3gcs37o+y8A8mydSRyb3ha8eaJSgCAewDXqwOPZ0XqV0M0hcpiZf4j2YOUmjahlt0GC2l0UuxoDZDLvYGSAsXju7V5WTKeFd3ejcWzpPMsaXwBQ6slXdR3oVIptVUqmVir0+lzHkgZbKpvR35gDysOn3Sdksno3kjZC0XZS6WsViOr1VJplObt36JSqZ4+fRoYGNiMZQIALKzpeh3gWdH4ArqzD8dSSJan7d+F1O4JRSQSTZky5eTJk7CDQINEhx+MmcHu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF+weXbB7dMHu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF3TdUygUw8v1kAVd93q9vqSkBHYKmKDrHoPdowt2jy7YPbpg9+iC3aMLdo8u2D26YPfogt2jC3aPLtg9umD36ILdowt2jy7IvVtx3LhxVVVVVCpVp9OVlZU5ODhQKBSNRnP69GnY0cwNcvU+Ojq6urpaJBKVlpYaum+IRCI0P9eFnPthw4YZPndoRK/Xh4WFwUsEDeTcAwBGjx5d/9NGDg4OsbGxUBPBAUX3Q4cOdXV1Nf4MDw/39fWFmggOKLoHAIwfP95Q9e3t7dGs9Oi6Hzx4sJubGwAgLCzMx8cHdhw4kPGjJNVlKnGFWqcjdi3D+087qTrZv8e451nEfqGNRqfYODL5AtL9qcl1fp+bIU2/KpbWaFz8uLKa5vxKBkR4VvSCx1I7V1bP4bYCOybsOK8hkfucDGnGVXHkGGcqrRWebddWqS4dFA2b7mxpQ5avqJDleP/iaV3apZp+41xapXgAgKWQOXyWx4G1BTrSfPGJLO7TUmq6D7OHnYJw3htmf/t0JewUryCFe51O//JpnYWQRMdCgrAQMopyFLBTvIIU7msr1Q5e0D4Db04sbZh6Hd7n14NCobSaVn3j6HVAUk2WLSWFewwUsHt0we7RBbtHF+weXbB7dMHu0QW7RxfsHl2we3TB7tEFu//H5Oc/jx0fNXTY+7CD/Fdam/u8vNyYMUOIK//CxTMzZo6nUlvD3601bEN9nj57RGj527ZvWLRw5YD+BP57mY2W6l4ilfy47fuxscMGDen5xdxpf55KBgD8si/+u/Vfl5aW9I4MOfL7/wAAVVWV36xZFjNmyPARfdesW/7yZYFh8WfZT3pHhly9dmnylJjekSHRH32wfcfGpqz3x8173u/Vl+CNMxOk6zjcRNav/7q8vDQubomHu1fyscObNq/z9PCe+Ml0lUp1OeXcoYMnAQBarfaLedNkMumC+V/5+QYc+i3hs5kT4uMTXZxd6TQ6ACAxce83qzfaCG1v3Lyy7tuvPD29Bw8a3vh63d09G5+hBdFS6316xv2IiMjQkK729g5Tp8zevm2fjY3dW/NkZqa9eJG/dMnq8LDuQqHNjOlxllaCpKSDxhl69uzj5OjMZDJ7v98vNLTbxYtnzL4dMGmp9T4wMPjwkUSxuCaoY+fQ0G4B/m3fnSczK43BYHTuFGr4SaFQgoO6pGfcN87g5xtgHHZxdrtwEa1H8Fuq+0ULVx4//vuly2cPH0nk8/hRUR+PHzeFTn9jc6RSiVqt7h0ZUn+kQGBtHGazOfWG2TKZ1CzZyUJLdW9pYRk7dtLYMROzstKvXb98IHEvn2/x0ag3nqq0sbHlcDhrvtlUfySNSjMOS6US47BCoaj/r4ACLdJ9XV3dmbMnBg0cxmazAwODAwODc3KePst+8tZsPj7+crnc3t7RxfnVE9fFoiKB1et6n5b+V48ery7R5OQ89fZC60nsFtnWo9Fo+xN2rVy1KCsrvaqq8ty5P7NzngR2CAYAuLq6V1ZWXL+e8vJlQZfOYWFh3TdsWF1aWiIW1yQfOzJ9xrgzZ44by7mXeuvO3ZsAgOs3Uh6kpfbtO7Dx9YrFNQ/SUh+kpYpERRqNxjBcUJBH/BYTAimexxNXqJN/Kh4xx6Ppi6Sn39+6/fvc3GwAgJeXz8gRowd+8CGVSq2srFiz9ssHaakTxk/9ZMJUnU53/ETS+QunHj3KdHPzCAnpOmfWAgDA8+c5k6fELF64Munor9k5T6lU6vDhH82eOb/xld6+fX3Jsri3RvbvP3jJoq+bGFsu1Z6IfzF5tVfTt5Q4Wqr7/4jB/ZZNuzt27GS2lZLNfYvc52OahRbZ1iOOJcvisjLTTE4aNGj4jOlv7/BbNIi69/b2vXwx9d3x8+d+qVKrTC7C5XCJz2VWEHXfEDY2trAjmA98vEcX7B5dsHt0we7RBbtHF+weXbB7dMHu0QW7RxdSuKdSgcC+9b9cDwCg1+ntXFlNmNEckMK9hZBRViBXyrWwgxBORbGCPC+NJYV7AIB/F4vSAjnsFIRTUaTwCeLBTvEKsrjvNdLu7qnymnLT99BaB5nXq+RSTdtQS9hBXkGKfjsGNCrd/7590a6bgG/NEDqwiP52gvnQg/IieXWpsq5WM/ATR9hpXkMi9wbuX64ufCbXA1BTQuw+QK/Xq1Sq+h/MIgihM4vOoHh14LYJIUuNN0A692ZDJBJNmTLl5MmTsINAgyzHe4z5we7RBbtHF+weXbB7dMHu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF+weXbB7dMHu0QW7RxfsHl2we3TB7tEFu0cXpN37+fnBjgATpN1nZ2fDjgATpN0jDnaPLtg9umD36ILdowt2jy7YPbpg9+iC3aMLdo8u2D26YPfogt2jC3aPLtg9uiD3bsVp06bJZDIqlapUKvPy8vz9/Q3Dv/32G+xo5ga572KGh4fv2LHD+PPJkycAAK229b++/V2Q2+ePHj3axcWl/hi9Xh8REQEvETSQc8/hcIYPH06nv97hWVhYTJgwAWooOCDnHgAQExPj6upq/BkUFNS5c2eoieCAonsOhzNs2DBD1bexsZk4cSLsRHBA0T0AIDo62s3NDQDQrl274OBg2HHg0KR2vkatk0tbzWcsDDAG9R+ZlJQUEz1RUq2BHaY50ev0ljaMpsz5N+f3j+/WZlwTV5WouHxa88XDEIiFLUOUK/fqwOvS19rBnd3InI25v3uuqqJYHdxLaCFs0v8RhiTodPraStW1o6URUXaufpyGZmvQ/Z0zVbWVmq5D7IkMiSGWP3e/7DHc1tXXtH7Tbb3qMlVFkRKLb+lEjnG6f7G6oamm3VcUKfV6sny+EfOvYfPo5YVKWa3pxqxp91Kx1s6tsWYCpqXg3oZX3cDX5kyf46mVOrWC4FAYsyCpVuuB6V04otd2MNg90mD36ILdowt2jy7YPbpg9+iC3aMLdo8u2D26YPfo0mzuR308cM/e7c1VGtFcv5EyZeqY3pEhDx9mNEuBm7d8O3HyR4bhYVGRCQf2NEuxz5/n9I4Mych40CylvQWi9f7XQ/v1QL/xh3gPD2/YWaCB3DNZBurqZEEdO3cKDoEdBCbN6Z5OZxz947f4nZuZTGaHDsFLFq+ysrQCAAwc3GPC+KkxH483zLb++1W5uc92xifm5eVO+vTjbT/+vGvP1oyMB44OTjExEzoFhyxfMb+w8EWbNu1nz1rQJqAdAEAqlR75PfHuvVv5+bk2Qtvu3XtNmjiDzWYDAIaP6Dvxk+licc3+hF0cDic0pNusmfNtbGwbCqnRaPoN6AoAyM9/fuz479t+/Ll9+45nzp44fiIpLy/Hy8u3T+/+I0eMplBe3fdsaFJdXd2adV8+eHDPy8t32NDod1f0R/LhM2eOFxW/7NwpbO4XSwUCawDArVvXLl0+m5H5oLZW3LZNh3HjPjX+/9VKanfu3HLq9DErK0FIl/Apn852cHB8q8yEA3sO/vrLpo272rZp/999Nec+/8rVCzKZ9Ltvty6Y/1VWVtovv/zU+PwMBgMAsG37hgnjp166cK99h6Dde7Zu3vLtooUrz56+yWKyfty63jDn0T8OHfx138cfjVu7ZvO0aZ+nXDm/P2GXsZDffkugUqnJf1zc/0tSZlbavv07G1kpnU6/fDHV09N72IfRly+mtm/f8cLFM9+t/9rfr83BxOOfTp75e9LBbTt+MMzcyKQNP6wuLHyx4fufVn+9IS8/9/ad6/XXcvr0serqyunT45Yt+SYtLXXb9g0AAIVCsWbdl0qlcvGir9eu2ezu7rnsyy+qqioN/5GLl8ypqCzf+EP87FkLyspLFy+do9G80d/mwsUzv+yLX75sbbOIb+Z6z+XyxsVONgzfuHklI7NJLZTIyA86dwoFALwf0ffixTMffhjdrm0HAEBEROSOnzbq9XoKhfLRqNheEZEeHl6GRbKy0u/euzlt6hzDTxcXt9ixkwAAgG8RGtLt2bPH/yj2qVPJHTt2ivt8MQDA2lo4ccL09RtWxY6ZZG0tbGiSVqu9nHJ+0cIVhqjTps65eetq/TI5XO7ET6Yb9hBDhoz4PemgSqVis9l7dh3icDhWVgIAQNs2HY4d/z0zK61XROTtO9cfP87a/8vv7u6eAAA3N4/DRxIN/xYG0tL++m79ymlT57z3Xq9/tHWN0JzuAzu8fsDFylKgUiqbspSbm6dhgMfnAwC8vXwNPzlsjlqtVqlULBaLwWDcS7317XcrcnKfGWqDtbXQWIK/f1vjsIWFpUwmbXpmnU6X9TB9/LgpxjGdOoXqdLqMzAc9e/RuaJLQ2gYAUL+dGBDQLjv7ifFnSJeuxqNGu3aB6kPqispyZyeXujrZnr3b0tL/qqysMEytqakGAOTmZnO5XIN4AIC/X5svl34DAJBKJQCAFy/z43dujuzzgfG42Sw07/H+dWnGLf9bqFRqIz8N7Nq99dSp5GnTPg8N6ebg4Lhn7/ZTp4/9i3W9i0qlUqvVe3/esffnHfXHV1dXNTKJRqMBALgcrnEkh/1GP2gul/d6EocLABCLa2hU2udffNq5U9jyZWvbtQukUCiGlgcAQCaTslgNdpDc8uN3Go1GKLT515tpEgjtfK3un73oQK/XnziZFD1yzJDBUYYxhtrQLLDZbC6X27/f4IiIyPrjnZ1cG5lUVlYCAFAoX/dprKuT1Z9HoZAbhw37ISsrQcqV8yqVavGirzkcjrHGG+ByeXJ5nU6nM/mvP6D/kDZt2v+wcU1ISFfD8bFZMId7JpMll9cZf758WfCPFler1XK53Nb21cMCKpXqrYPrf8THx18ilRjb22q1WiQqsrd3aGSSwVBWVnqAf1vD+NS/7hha8gZycp4ah58+fcRkMu1s7WtrxRYWlgbxAIArVy8a52kT0E6hUDx99tjQjnvxIn/j5rWzZy4w7NL69xvcsWOne/durVn75c97DxvOnv475ri2065d4JWrF6VSKQDgQOLeioqyf7Q4k8l0d/c8feZ4UXGhWFyzfsOqwA7BEkmtTCZrwtJ/z5TJs27cSDl1+phOp8vMTFu1esnc+dNVKlUjk+zs7Dt0CNq3L/7lywKlUvnNmmVvHXfy8nMPH0nUarXPsp+cPXcyomcfBoPh7e1XWVlx/ESSRqO5c/fm/ft3rawEhl1ISEhXFxe3Xbt+vHb98r3U25u3fFteVmps2xpYuGAFnU7/9rsVzbLVZnI/a+Z8obXN0GHv9xvQValURPb54J+WsHzZWjaL/cnE6Njxw7t0Dvv001lsFjtqZF9RSfF/jxcYGLwr/n8ZGQ+iRvabv/AzmUz6zeqNLBar8UlLFq9q27bD1OljBw+NsLCwHDRwmPHpNo1GPSp67MOHGX37h8+dNy2wQ/CsmfMBAJF9BoyLnZxwYHe/AV2Tkg7Omb2wX99BB3/dt3HTWjqdvmH9Dp1e99WKBQsXzWJzOOvWbqnffgIA8Hi8Fcu/vXPnxtE/mue1UKafx7t7tkqlAEHvC00tgmlJnD9QFNpf6OZv4pE8RK/nY1rt9fzMzLSly+Iampp4INlwdQVxWqf7wMDgXbsONjQVizfQOt0DAJwcnWFHIDv4eI8u2D26YPfogt2jC3aPLtg9umD36ILdowt2jy6mr+sx2RRdAy9nwrQsLKwZlAYquOnRFtaM8gK5yUmYlkX+I6mNI9PkJNPu7d1Y/6H/I4YsyGrUzl4cTgPvQG+w3rv4sq8mlRCcDUMsF/5XHPqBdUNTG3uH+sNb4uw0aVAvG2sHJo2OW4UtBkWdVlyuvP5H2ZApTrbOrIZm+5tvJ+Q9lKVdqSnJU9AYrfAYoNXqaLTW9j9tbc8Ul6u8OvBC+wsb/4BGU7+LqZS3sm+mgJKSks8//7z1fQ5TrwNsXpP+oZvad4PFaW31g8mmaHTy1rddTQfdLcdg9+iC3aMLdo8u2D26YPfogt2jC3aPLtg9umD36ILdowt2jy7YPbpg9+iC3aMLdo8u2D26YPfogt2jC3aPLtg9umD36IK0+4CAANgRYIK0+6dPnzZhrlYL0u4RB7tHF+weXbB7dMHu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF+weXbB7dGnqezVbDZs2bTpw4MBbI3U6XVpaGqRE0ECu3sfExHh5eVHrAQAIDQ2FnQsCyLl3cnLq3bs3pd7nAYRC4fjx46GGggNy7gEAo0aN8vT0NP709PTs2bMn1ERwQNG9g4NDRESEoeoLBIJx48bBTgQHFN3Xr/peXl69evWCHQcOiLp3dHTs0aMHn88fO3Ys7CzQIN053q0/K18+k9MZlIpiJaEr0uuBVqOhM5r6BYF/jb0bS68D3oG8oAgB0ev6R5DIvUqh+2VFXvgQewtrusCORZZY/xmKXl8hUlYWK0oL5FGfucCO8xqyuNfr9DsW5I5e5M1gtdrD0LP74vws6cjZZNFPFveXDpc5+/JcfHiwgxBLxrUqS2ta4HtWsIMAErX1su9L7Fw5sFMQjrU9K/+RDHaKV5DCfW2V2tmHy2y9e3sjNk4sPWk+OEaKP7deB6pKVLBTmAMKlVJeSOz5S9MhhXsMFLB7dMHu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF8J7LLUyHj7M+PW3/RkZD+h0up9vQEzMhE7BIbBD/UtaW73Py8uNGTOEoMJfvMift2CGRFI7fdrnY0Z/UlIqWrosrrKygqDVEU1rq/dPnz0irvAjv//P1sZu0w87Xz3JFdLtk0mj0tL/iuwzgLiVEkdLdS+RSn7ZF3/n9vXqmqoA/3Z9+w4cPGj4L/viEw7sAQD0jgz5bMYXo6LHVlVV7vhpY9bDdIVCERrabXzsp25uHgCAZ9lPpk2P/Xrl+v0Ju54/z7Gxse39fv+Zn81tfKXz5i6r/5POYAAAmEwmwdtKFC3V/fr1X5eXl8bFLfFw90o+dnjT5nWeHt4TP5muUqkup5w7dPAkAECr1X4xb5pMJl0w/ys/34BDvyV8NnNCfHyii7MrnUYHACQm7v1m9UYboe2Nm1fWffuVp6f34EHDmxigqLhw7brlgYHB4WHvEbytRNFSj/fpGfcjIiJDQ7ra2ztMnTJ7+7Z9NjZ2b82TmZn24kX+0iWrw8O6C4U2M6bHWVoJkpIOGmfo2bOPk6Mzk8ns/X6/0NBuFy+eacqqH6Sl9o4MiR03XKNWr171Q8ut9y3VfWBg8OEjiT/Fb75586parQ7wb+vo6PTWPJlZaQwGo3OnV89XUyiU4KAu6Rn3jTP4+b7+boaLs1t+wfOmrNrHx3/jD/HLln4jk0k/j/sUt/XMzaKFK48f//3S5bOHjyTyefyoqI/Hj5tCp7+xOVKpRK1W94584xxMILA2DrPZnHrDbJlM2pRVW1pYGs7runeLiBkz5NjxI5MmzmiObTI3LdW9pYVl7NhJY8dMzMpKv3b98oHEvXy+xUejYuvPY2Njy+Fw1nyzqf5IGpVmHJZKJcZhhUJR/1/BJHfu3tTr9V3DXx3guVyus5NLfn6T9hYkpEW6r6urO3P2xKCBw9hsdmBgcGBgcE7O02fZT96azcfHXy6X29s7uji7GsYUi4oEVq/rfVr6Xz16vG8Yzsl56u3l2/h6jx79taam2uheoVAUFb9s3yGoWTfOfLTI4z2NRtufsGvlqkVZWelVVZXnzv2ZnfMksEMwAMDV1b2ysuL69ZSXLwu6dA4LC+u+YcPq0tISsbgm+diR6TPGnTlz3FjOvdRbd+7eBABcv5HyIC21b9+Bja83KirmWfaTH7euf5CW+iAtdfWapRqN5sMhI4nfYkIgxTNZ4gp18k/FI+Z4NH2R9PT7W7d/n5ubDQDw8vIZOWL0wA8+pFKplZUVa9Z++SAtdcL4qZ9MmKrT6Y6fSDp/4dSjR5lubh4hIV3nzFoAAHj+PGfylJjFC1cmHf01O+cplUodPvyj2TPn/+16z53789ff9hv284GBwZMnfhYU1LnpseVS7Yn4F5NXezV9EeJoqe7/Iwb3Wzbt7tixk9lWSjb3LXKfj2kWWmRbjziWLIvLyjT9or1Bg4bPmB5n9kQEgqh7b2/fyxdT3x2/fNlarU5rchEGnUF8LrOCqPuG4HK5sCOYD3y8RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RhRTudTpgZdParpqZhEIFAluybCkp3FvbMwqz62CnMAfichWgNGE+s0AK9wAAr0BeTQVZXjxHHLVVKlc/srw+lCzuu0RaX0sqhZ2CWDRq3Z0/K8IH2sAO8gpS9N0wUJgjv55c0TvGkWtBliNiM1JeJE85VBKzwJ1rQWtRdtJyAAAIDElEQVTC7OaARO4BAEW58vuXqksLFG4BfGm1mtB16QHQabU0GuEm+Nb05xlS7468XiPt2FyyiCedewNyqba6VEV0rsrKyg0bNqxbt47Y1QBApVHsXJl0BlkOr0bIeP+ew6dx+IQ3iKg8WpU8x8WXLC0v80O6f0aM2cDu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF+weXbB7dMHu0QW7RxfsHl2we3TB7tEFu0cX7B5dsHt0we7RBWn3bm5usCPABGn3L1++hB0BJki7RxzsHl2we3TB7tEFu0cX7B5dsHt0we7RBbtHF+weXbB7dMHu0QW7RxfsHl2we3TB7tGFjO/VJJS5c+empKRQKBQAgF6vNw7cv38fdjRzg1y9nzZtmrOzM4VCoVAoVCrVMODj4wM7FwSQcx8QENCp0xvfPWcymWPGjIGXCBrIuQcAjB8/3tHR0fjT1dU1KioKaiI4oOjez8+vc+fOhmEWi/XRRx/BTgQHFN0DAMaOHWtvb2/oph0dHQ07DhwQdR8QEBAaGspgMJCt9C3jHK+kQFGSLxdXaKRiLY1BlVQ1z/c01CpVcbHIw9OjWUoDAPAs6FQa4FnRhI4MFx+OwI7ZXCUTBHndVxQp718W5z+SMTl0rpBDpVHpTBqDTQckzQv0er1aqdEotQAAsUjCYFLahPA79bZmskm6cyWje0m1+srRyvJClZWzpaUdl84i0Tdmmo5CqqqrlpdmVwf2ELw3VEihkua7eP8P6dzfOVuTdUNs4ykQOPFhZ2keyp/XKMR1vaLt3P3ZsLO8Abncnz1QWlNFcfAnyxfkmgu9Xl9wXxQcYREcIYCd5TUkcn/hUHmthCZ0tYIdhCiKHpaFRPIDOlnADvIKsrg/uUek0rGEbq1WvIHix2XtQzhB5Kj9pGiC3jlTpVDSW714AIBzW/v0a5Li56T48DN894XZdYW5KltvIewgZsK9s/OVpEqdFv7uFr77a8mVHBtL2CnMCsuSe+NEBewUsN3npEv0FBrXigU3hpkRugse3ZYoZFq4MSC7z7gmFbqTouFjku+3jk46sZ6Iku19hakXa4gouenAdC+pVleKFGwLtCq9AZ41O/u+BG4GmO7zHsos7LgQA0CEyWXoAaWqRAUxA8zvYJcXqni2PIIK12o1py/EP352o6amxMsjqHv4qHYB7xkmrVg3YEDkVFldzblLe1hMToBf12ED51pa2gIASsqeH0paVVqe5+vdpW+vSQRlM2Dtwi/KrRM6QrvdB7Pei/IUDCZR92n+OLnh2q1fe4SPWjovObB9n4RDizOyLhkm0WiMlOuJFAp11ZJzC+cczitIP3t5NwBAo1HvSYgTWNkvnPPb4P6zUq4nSiQEtsZ1OkpVSfPcj/53wHRfJ9EQdI9OrVampv3Zp+eEbmEjeFyr8C4fduo44HzKXuMMtkLXvr0mcjgWlpa2Ab5dC4ueAAAyH12uEZd+OPALa4Gjo7131JD5cgWBh2Q6ky6t0RBX/t8Czb1Wo6MzqXRi6v3L4scajcrfN9w4xsezs6g0R1YnNvx0dWlrnMThWCqUUgBAReVLJoMttHYyjLe0sBVYORARzwCDTVOpYF7hgXa8p9Gp8lqNXqcn4sa2Qi4FAGzfM/Wt8RJpJY9ruHJsYqV18lom6422J4NO4F1XnVavVSPpHgDA5tM0Ki2D3fwZDA236GFLbIVvvDHX2sqx4YUAl2OpVL5xpV2hlDV7NiMapZZvBfPvD3PdXAu6WqEhwr2djTuDwQIA+Hp3MYyRSKv0ej2L1dgppbXASa1WiEpznBx8AQBFome1kvJmz2ZErdTY2cHskgSzrefgwVbJCWnosljc/r2nnL+893lBmlqjysi6tGvf7KMn/+YKXfu2EXQ680jyOpVKIa4tTzz8JZdL4K1FvVZj6wLzuhbMeu/RhnP7bK3AiZC+DL17jnN28r98LSE79x6bzfd0Cxw1bGnji3DY/MmxG/88t+3LNX2YDPbg/rPuZ5wlrpddVaHMo60tYcX/PTD7buh0+h3zczv084IVACKyaoVUVP3xPFeIGWDu86lUin8XS0kFKToymJm6anm7bpA7o8Lc5wMAQvsJjm4TWdg22ATbvf/zgsIsk5O0Wg2NZjp/zIivOrTt1VwhL13df+lagslJHBZfrpSanPTZ5HhnRz+Tk9RKTU2xJHAm5B0e/P56ZxJK5SqWtYvpo35tbYVGa/qGh0qtZDJMt5X4PCGT2Wyn5nK5pKELfCqVoqEVWVrY0ekMk5OKHpZ1juC1DYPcYwW+e7VSd2RLkXOgM9wYZkNeq1SLxR9OdYIdBHbfDQAAg0Xt87FtwV9FsIOYA51Wl3dPRAbxpHAPAHD04IT2E7zMKIUdhHDy7xXFLnGHneIV8Pf5RvIe1l0/Ue0W1Nhl15aLWqHJvV00bpk7zxJy+9oIidwDAPIeyc4fKHMLduBYtqqOXLVlsrLsyrFL3Dk8Ej1XSi73AABZrebELpFGR7PzEbK4ptvJLQhJRV3582p3f3bf0faws7wN6dwbyM2QXjlaQWMy+LZcSzsuEfd7CEUuUUrK6tRyFZOpfz/a1g7qdfuGIKl7Ay+e1D35S1rwWMbmM7RqPZ1JY/JYWo0Odi7TUKhAXafWqDQsLl2j1PgE8vw68ezdyPXcdX1I7d5ITbmqTqKtq9WqlDqVgqTuWRwqi0PlWdJ5VnS+oAXsqFqGewwRkOL8HgMF7B5dsHt0we7RBbtHF+weXf4PujMWu02qrqIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#show_graph(graph)\n",
        "# Show\n",
        "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "028372b5-88ae-4f13-813d-22430a697f07",
      "metadata": {
        "id": "028372b5-88ae-4f13-813d-22430a697f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3681ea8b-95e8-4a1d-bc4a-b9b182b1e8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Step 1---\n",
            "{'step_1': None}\n",
            "\n",
            "\n",
            "---human_feedback---\n",
            "{'__interrupt__': (Interrupt(value='Please provide feedback:', id='7300de8464fc85a62e99e33e3c7d9a8b'),)}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Input\n",
        "initial_input = {\"input\": \"hello world\"}\n",
        "\n",
        "# Thread\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Run the graph until the first interruption\n",
        "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f142d467-7b4c-4a04-bad5-bf3fbe953b84",
      "metadata": {
        "id": "f142d467-7b4c-4a04-bad5-bf3fbe953b84"
      },
      "source": [
        "To resume from an interrupt, we can use [the `Command` object](https://langchain-ai.github.io/langgraph/how-tos/command/).\n",
        "\n",
        "We'll use it to resume the graph from the interrupted state, passing the value to return from the interrupt call to `resume`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d90374d3-65a1-4658-82ee-a16cc2835cf4",
      "metadata": {
        "id": "d90374d3-65a1-4658-82ee-a16cc2835cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29162a9-c1bf-49dc-88f3-2b657e22e522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---human_feedback---\n",
            "{'human_feedback': {'user_feedback': 'go to step 3!'}}\n",
            "\n",
            "\n",
            "---Step 3---\n",
            "{'step_3': None}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Continue the graph execution\n",
        "for event in graph.stream(\n",
        "    Command(resume=\"go to step 3!\"),\n",
        "    thread,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8639a518",
      "metadata": {
        "id": "8639a518"
      },
      "source": [
        "### Tracing\n",
        "\n",
        "When we are using LangChain or LangGraph, LangSmith logging [will work out of the box](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph) with the following environment variables set:\n",
        "\n",
        "```\n",
        "export LANGSMITH_TRACING=true\n",
        "export LANGSMITH_API_KEY=\"<your-langsmith-api-key>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb2a3e5",
      "metadata": {
        "id": "9cb2a3e5"
      },
      "source": [
        "Here is the LangSmith trace from above agent execution:\n",
        "\n",
        "https://smith.langchain.com/public/6f77014f-d054-44ed-aa2c-8b06ceab689f/r\n",
        "\n",
        "We can see that the agent is able to continue the conversation from the previous state because we used a checkpointer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0269214",
      "metadata": {
        "id": "f0269214"
      },
      "source": [
        "### Deployment\n",
        "\n",
        "We can also deploy our graph using [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/).\n",
        "\n",
        "This creates a server [with an API](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html) that we can use to interact with our graph and an interactive IDE, LangGraph [Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/).\n",
        "\n",
        "We simply need to ensure our project has [a structure](https://langchain-ai.github.io/langgraph/concepts/application_structure/) like this:\n",
        "\n",
        "```\n",
        "my-app/\n",
        "├── src/email_assistant # all project code lies within here\n",
        "│   └── langgraph101.py # code for constructing your graph\n",
        "├── .env # environment variables\n",
        "├── langgraph.json  # configuration file for LangGraph\n",
        "└── pyproject.toml # dependencies for your project\n",
        "```\n",
        "\n",
        "The `langgraph.json` file specifies the dependencies, graphs, environment variables, and other settings required to start a LangGraph server.\n",
        "\n",
        "To test this, let's deploy `langgraph_101.py`. We have it in our `langgraph.json` file in this repo:\n",
        "\n",
        "```\n",
        " \"langgraph101\": \"./src/email_assistant/langgraph_101.py:app\",\n",
        "```\n",
        "\n",
        "For LangGraph Platform, there are a range of [deployment options](https://langchain-ai.github.io/langgraph/tutorials/deployment/):\n",
        "\n",
        "* Local deployments can be started with `langgraph dev` from the root directory of the repo. Checkpoints are saved to the local filesystem.\n",
        "* There are also various [self-hosted options](https://langchain-ai.github.io/langgraph/tutorials/deployment/#other-deployment-options).\n",
        "* For hosted deployments, checkpoints are saved to Postgres using a postgres [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries).\n",
        "\n",
        "Test:\n",
        "```\n",
        "Draft a response to my boss (boss@company.ai) confirming that I want to attent Interrupt!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3644093",
      "metadata": {
        "id": "f3644093"
      },
      "source": [
        "Here we can see a visualization of the graph as well as the graph state in Studio.\n",
        "\n",
        "![langgraph_studio](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/img/langgraph_studio.png?raw=1)\n",
        "\n",
        "Also, you can see API docs for the local deployment here:\n",
        "\n",
        "http://127.0.0.1:2024/docs"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}